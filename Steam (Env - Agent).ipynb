{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steam (Environment - Agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "# Basic import\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from scipy.stats import norm\n",
    "import pdb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout, Dot, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self, nb_films, nb_users, \n",
    "                 context_size = 2,\n",
    "                 displayed_users_embedding_size = 2, #used for the features vector\n",
    "                 displayed_games_embedding_size = 2, #used for the features vector\n",
    "                 noise_size = 3,\n",
    "                 rating_probability = 0.5,\n",
    "                 std_dev_playtime = 0.15,\n",
    "                 refund_threshold = 0.1,\n",
    "                 seed=None):     \n",
    "        self._rng = np.random.RandomState(seed)\n",
    "        self._rating_probability = rating_probability \n",
    "        self._std_dev_playtime = std_dev_playtime\n",
    "        self._refund_threshold = refund_threshold\n",
    "        #-------------------------------------------------------#\n",
    "        self._nb_games = nb_games\n",
    "        self._nb_users = nb_users\n",
    "        self._p = context_size # size of user, size of game\n",
    "        self._displayed_users_embedding_size = displayed_users_embedding_size\n",
    "        self._displayed_games_embedding_size = displayed_games_embedding_size\n",
    "        self._noise_size = noise_size\n",
    "        #-------------------------------------------------------\n",
    "        self.user_mean = np.ones(self._p)\n",
    "        self.user_var = np.ones(self._p)\n",
    "        self.game_mean = np.ones(self._p)\n",
    "        self.game_var = np.ones(self._p)\n",
    "        #-------------------------------------------------------#\n",
    "        self.finish = False # True = all games have been played\n",
    "    \n",
    "    def step(self):\n",
    "        if self.finish == True or self._available_games.sum() == 0: \n",
    "            # all players played all games\n",
    "            self.finish = True\n",
    "            print(\"All games played reset the environment\")\n",
    "            return 0, 0, self.finish\n",
    "        \n",
    "        user = self.get_next_user() # pick a user\n",
    "        available_games = np.where(self._available_games[user] == 1)[0]\n",
    "        optimal_reward = np.max(self._reward_matrix[user,available_games])\n",
    "        return user, available_games, optimal_reward, self.finish\n",
    "    \n",
    "    def get_next_user(self):\n",
    "        user = self._rng.randint(0, self._nb_users)\n",
    "        if np.sum(self._available_games[user,:]) > 0: \n",
    "            # still some games to play for user\n",
    "            return user\n",
    "        else: \n",
    "            # all games played for the current user\n",
    "            # find a random player between the ones who have some games left to play\n",
    "            row,cols = np.where(self._available_games == 1)\n",
    "            return self._rng.choice(row)\n",
    "    \n",
    "    def update(self, user, game):\n",
    "        reward = self._reward_matrix[user, game]        \n",
    "        self._available_games[user, game] = 0\n",
    "        return reward\n",
    "    \n",
    "    def reset(self):\n",
    "        self.finish = False\n",
    "        self._users = self._rng.normal(loc=self.user_mean,\n",
    "                                                scale=self.user_var,\n",
    "                                                size=(self._nb_users, self._p))\n",
    "        self._games = self._rng.normal(loc=self.game_mean,\n",
    "                                                scale=self.game_var,\n",
    "                                                size=(self._nb_games, self._p))\n",
    "        \n",
    "        z_mean = self.user_mean.dot(self.game_mean)\n",
    "        z_var = self.user_var.dot(self.game_var) + self.user_var.dot(np.square(self.game_mean)) + \\\n",
    "                self.game_var.dot(np.square(self.user_mean))\n",
    "        z = norm(z_mean, np.sqrt(z_var))\n",
    "        self.z_cut_points = z.ppf([0.2, 0.4, 0.6, 0.8]) # buckets\n",
    "        \n",
    "        self._available_games = np.ones((nb_users, nb_games))\n",
    "        # rating generation based on (user âˆ™ game)\n",
    "        self._rating_matrix = np.zeros((nb_users, nb_games))     \n",
    "        for i in range(self._rating_matrix.shape[0]):\n",
    "            for j in range(self._rating_matrix.shape[1]):\n",
    "                real_score = self._users[i].dot(self._games[j])\n",
    "                self._rating_matrix[i, j] = np.searchsorted(self.z_cut_points, real_score) / 4\n",
    "        # playtime generation\n",
    "        # for simulation purposes, such playtime (always > 0) is based on the similarity \n",
    "        # between the user profile and the game (i.e. like a reward) + some noise\n",
    "        # and some non-linear function (i.e. abs + clip)\n",
    "        self._playtime_matrix = deepcopy(self._rating_matrix)\n",
    "        self._playtime_matrix += self._rng.normal(loc = 0.0, scale = self._std_dev_playtime, size = (nb_users, nb_games))\n",
    "        self._playtime_matrix = np.clip(np.abs(self._playtime_matrix), 0, 1)\n",
    "        # reward matrix generation\n",
    "        self._reward_matrix = np.zeros((nb_users, nb_games))\n",
    "        rating_probability = self._rng.binomial(1, self._rating_probability, size=(nb_users, nb_games))\n",
    "        for i in range(self._reward_matrix.shape[0]):\n",
    "            for j in range(self._reward_matrix.shape[1]):\n",
    "                if self._playtime_matrix[i, j] < self._refund_threshold:\n",
    "                    self._reward_matrix[i, j] = self._playtime_matrix[i, j]\n",
    "                else:\n",
    "                    if rating_probability[i, j] == 1:\n",
    "                        self._reward_matrix[i, j] = self._rating_matrix[i, j]\n",
    "                    else:\n",
    "                        self._reward_matrix[i, j] = self._playtime_matrix[i, j] / np.sum(self._playtime_matrix[i, :])\n",
    "\n",
    "        users = deepcopy(self._users)\n",
    "        return users\n",
    "\n",
    "    def get_feature_vector(self, user, game):\n",
    "        user_embedding = self._users[user]\n",
    "        game_embedding = self._games[game]\n",
    "        \n",
    "        if self._displayed_users_embedding_size + self._displayed_games_embedding_size > 0:\n",
    "            variables = np.array([user_embedding[:self._displayed_users_embedding_size],\n",
    "                                  game_embedding[:self._displayed_games_embedding_size]])\n",
    "\n",
    "            if self._noise_size > 0:\n",
    "                noise = self._rng.normal(loc=np.ones(self._noise_size),\n",
    "                                         scale=np.ones(self._noise_size),\n",
    "                                         size=self._noise_size)\n",
    "                \n",
    "                variables = np.append(variables, noise)\n",
    "                \n",
    "        return variables\n",
    "        \n",
    "        \n",
    "    def reset_seed(self, seed=None):\n",
    "        self._rng = np.random.RandomState(seed)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "    def __init__(self, seed = None):\n",
    "        self._rng = np.random.RandomState(seed)\n",
    "    \n",
    "    def act(self, available_games):\n",
    "        action = self._rng.choice(available_games)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic parameter\n",
    "nb_users = 30 #number of users in the context = 30\n",
    "nb_games = 10 #number of games in the context = 10\n",
    "context_size = 2 #number of different film categories = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76884571,  1.07555227],\n",
       "       [-0.1306297 ,  0.34856983],\n",
       "       [ 0.10688437, -0.27410098],\n",
       "       [ 0.93884557,  1.06451384],\n",
       "       [ 1.41011295,  0.42711751],\n",
       "       [ 0.19866638,  2.31203519],\n",
       "       [ 2.27469887, -0.2143576 ],\n",
       "       [ 1.31371941, -0.44482142],\n",
       "       [ 0.6310387 ,  0.23077342],\n",
       "       [ 1.3926161 ,  1.05729383],\n",
       "       [ 3.08997884,  1.04197131],\n",
       "       [ 0.95165928,  0.48684608],\n",
       "       [ 0.91541072, -0.21545008],\n",
       "       [-0.41293073, -0.48691055],\n",
       "       [ 1.38222486,  1.937673  ],\n",
       "       [ 2.77267804,  1.87882801],\n",
       "       [ 1.33171912,  0.69396433],\n",
       "       [ 2.24026615,  0.78437316],\n",
       "       [ 1.15592948,  1.09805553],\n",
       "       [ 1.83209585,  3.04520542],\n",
       "       [ 0.68318608, -0.31283291],\n",
       "       [-0.75445746,  1.10209408],\n",
       "       [-0.36150208,  1.48178488],\n",
       "       [ 0.79167126,  0.90813649],\n",
       "       [ 1.70268816,  1.10365506],\n",
       "       [ 1.62123638,  1.95411497],\n",
       "       [ 3.03781352,  0.51554878],\n",
       "       [ 1.2071549 ,  2.64424216],\n",
       "       [ 0.5117926 ,  0.98217174],\n",
       "       [ 1.46891556,  1.27987266]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the environment\n",
    "env = Environment(nb_games,nb_users,context_size,seed=2020,rating_probability=0.7)\n",
    "env.reset() #reset and initilize the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the agent\n",
    "agent = RandomAgent(2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the experiment and generate some historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward matrix: \n",
      " [[0.         0.         0.09883591 0.5        0.         0.\n",
      "  0.15731846 0.25       0.         0.        ]\n",
      " [0.         0.         0.         0.25       0.         0.\n",
      "  0.25       0.         0.1509283  0.        ]\n",
      " [0.0827172  0.         0.         0.02537533 0.         0.03269443\n",
      "  0.         0.019173   0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.0972486  0.5        0.         0.25      ]\n",
      " [0.25       0.10036821 0.         0.         0.         0.\n",
      "  0.         0.         0.07247928 0.25      ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.03847896]\n",
      " [0.08454433 0.         1.         0.         1.         0.\n",
      "  0.05875463 0.5        0.         0.        ]\n",
      " [0.25       0.         0.         0.06849893 0.         0.\n",
      "  0.07317941 0.         0.05228926 0.        ]\n",
      " [0.25       0.         0.         0.25       0.         0.\n",
      "  0.03761376 0.         0.         0.25      ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.11566137 0.         0.25      ]\n",
      " [0.         0.         1.         0.25       0.16465294 0.\n",
      "  0.02894169 0.         0.         0.        ]\n",
      " [0.         0.09641297 0.5        0.09717896 0.75       0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.05912833 0.         0.         0.08775769 0.         0.25\n",
      "  0.         0.09828041 0.         0.09752073]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.13256506]\n",
      " [0.         0.75       0.         0.         0.         0.\n",
      "  0.         0.11551153 0.         0.        ]\n",
      " [0.5        1.         0.         0.         0.         1.\n",
      "  0.         0.12746748 0.         0.        ]\n",
      " [0.         0.         0.5        0.25       0.         0.\n",
      "  0.         0.17173781 0.5        0.25      ]\n",
      " [0.25       0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.04024741 0.75       0.5\n",
      "  0.03359411 0.         0.75       0.25      ]\n",
      " [0.         0.         0.         0.75       0.         1.\n",
      "  0.         0.         0.         0.25      ]\n",
      " [0.         0.         0.         0.         0.         0.0413819\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.25       0.25       0.         0.         0.         0.\n",
      "  0.         0.5        0.         0.        ]\n",
      " [0.         0.         0.         0.25       0.         0.\n",
      "  0.         0.         0.         0.25      ]\n",
      " [0.         0.5        0.75       0.         0.         0.\n",
      "  0.         0.         0.13212354 0.        ]\n",
      " [0.         0.         0.75       0.         1.         0.75\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.01808189 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.5        0.         0.14047911 1.\n",
      "  0.25       0.         0.         0.        ]\n",
      " [0.25       0.5        0.1111722  0.05959767 0.5        0.\n",
      "  0.         0.         0.         0.25      ]\n",
      " [0.         0.         0.75       0.         1.         0.75\n",
      "  0.         0.11724588 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Running several trials\n",
    "nb_iteration = 100 #how many trials\n",
    "reward_matrix = np.zeros((env._nb_users, env._nb_games))\n",
    "users = list()\n",
    "games = list()\n",
    "rewards = list()\n",
    "for i in range(nb_iteration):\n",
    "    user, available_games, _, finish = env.step()\n",
    "    if finish:\n",
    "        print(\"Maybe too many trial try to reduce and reset the environment\")\n",
    "        break\n",
    "    choosen_game = agent.act(available_games)\n",
    "    reward = env.update(user, choosen_game)\n",
    "    users.append(user)\n",
    "    games.append(choosen_game)\n",
    "    rewards.append(reward)\n",
    "    reward_matrix[user, choosen_game] = reward\n",
    "    '''\n",
    "    print(\"user = {}, recommended_games = {}, choosen_game = {}\".format(user,recommended_games,choosen_game))\n",
    "    print(\"reward = {}\\n\".format(reward))\n",
    "    '''\n",
    "print(\"reward matrix: \\n\", str(reward_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(Model):\n",
    "    def __init__(self, embedding_size, max_user, max_game):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_embedding = Embedding(output_dim=embedding_size,\n",
    "                                        input_dim=max_user,\n",
    "                                        input_length=1,\n",
    "                                        name='user_embedding')\n",
    "        self.game_embedding = Embedding(output_dim=embedding_size,\n",
    "                                        input_dim=max_game,\n",
    "                                        input_length=1,\n",
    "                                        name='game_embedding')\n",
    "        self.flatten = Flatten()\n",
    "        self.dot = Dot(axes=1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        user_inputs = inputs[0]\n",
    "        game_inputs = inputs[1]\n",
    "        \n",
    "        user_vecs = self.flatten(self.user_embedding(user_inputs))\n",
    "        game_vecs = self.flatten(self.game_embedding(game_inputs))\n",
    "        \n",
    "        y = self.dot([user_vecs, game_vecs])\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepRegressionModel(Model):\n",
    "\n",
    "    def __init__(self, embedding_size, max_user, max_game):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_embedding = Embedding(output_dim=embedding_size,\n",
    "                                        input_dim=max_user,\n",
    "                                        input_length=1,\n",
    "                                        name='user_embedding')\n",
    "        self.game_embedding = Embedding(output_dim=embedding_size,\n",
    "                                        input_dim=max_game,\n",
    "                                        input_length=1,\n",
    "                                        name='game_embedding')\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.concat = Concatenate()\n",
    "        \n",
    "        self.dropout = Dropout(0.9)\n",
    "        self.dense1 = Dense(16, activation=\"relu\")\n",
    "        self.dense2 = Dense(8, activation=\"tanh\")\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        user_inputs = inputs[0]\n",
    "        game_inputs = inputs[1]\n",
    "        feature_inputs = inputs[2]\n",
    "        \n",
    "        user_vecs = self.flatten(self.user_embedding(user_inputs))\n",
    "        game_vecs = self.flatten(self.game_embedding(game_inputs))\n",
    "        \n",
    "        input_vecs = self.concat([user_vecs, game_vecs, self.flatten(feature_inputs)])\n",
    "        \n",
    "        y = self.dropout(input_vecs, training=training)\n",
    "        y = self.dense1(y)\n",
    "        y = self.dense2(y)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingAgent:\n",
    "    def __init__(self, X, Y, deepRegression=False):\n",
    "        if deepRegression:\n",
    "            self._model = DeepRegressionModel(64, nb_users, nb_games)\n",
    "        else:\n",
    "            self._model = RegressionModel(64, nb_users, nb_games)\n",
    "        self._model.compile(optimizer=\"adam\", loss='mae')\n",
    "        self._model.fit(X, Y,\n",
    "                  batch_size=64, epochs=100, validation_split=0.1,\n",
    "                  shuffle=True)\n",
    "        self._user_embeddings = self._model.get_weights()[0]\n",
    "        self._game_embeddings = self._model.get_weights()[1]\n",
    "    \n",
    "    def act(self, user, available_games):\n",
    "        user_embedding = self._user_embeddings[user]\n",
    "        dot_products = self._game_embeddings @ user_embedding\n",
    "        user_embedding_norm = np.linalg.norm(user_embedding)\n",
    "        all_item_norms = np.linalg.norm(self._game_embeddings, axis=1)\n",
    "        norm_products = user_embedding_norm * all_item_norms\n",
    "        sims = dot_products / (norm_products)\n",
    "        sims = np.argsort(sims)[::-1]\n",
    "        mask = np.in1d(sims, available_games)\n",
    "        sims = sims[mask]\n",
    "        return sims[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.9 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Large dropout rate: 0.9 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "64/90 [====================>.........] - ETA: 0s - loss: 0.4866WARNING:tensorflow:Large dropout rate: 0.9 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "90/90 [==============================] - 0s 731us/sample - loss: 0.4710 - val_loss: 0.3113\n",
      "Epoch 2/100\n",
      "WARNING:tensorflow:Large dropout rate: 0.9 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "64/90 [====================>.........] - ETA: 0s - loss: 0.4958WARNING:tensorflow:Large dropout rate: 0.9 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "90/90 [==============================] - 0s 571us/sample - loss: 0.4723 - val_loss: 0.3060\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 0s 427us/sample - loss: 0.4774 - val_loss: 0.3007\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 0s 456us/sample - loss: 0.4616 - val_loss: 0.2954\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 0s 500us/sample - loss: 0.4314 - val_loss: 0.2901\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 0s 509us/sample - loss: 0.4381 - val_loss: 0.2847\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 0s 444us/sample - loss: 0.4455 - val_loss: 0.2794\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 0s 408us/sample - loss: 0.4789 - val_loss: 0.2740\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 0s 523us/sample - loss: 0.4580 - val_loss: 0.2688\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 0s 567us/sample - loss: 0.4597 - val_loss: 0.2635\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 0s 578us/sample - loss: 0.4222 - val_loss: 0.2585\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 0s 554us/sample - loss: 0.4041 - val_loss: 0.2536\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 0s 568us/sample - loss: 0.4153 - val_loss: 0.2493\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 0s 545us/sample - loss: 0.4022 - val_loss: 0.2452\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 0s 1ms/sample - loss: 0.3953 - val_loss: 0.2411\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 0s 581us/sample - loss: 0.4026 - val_loss: 0.2369\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 0s 550us/sample - loss: 0.3982 - val_loss: 0.2328\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 0s 479us/sample - loss: 0.3792 - val_loss: 0.2290\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 0s 373us/sample - loss: 0.4204 - val_loss: 0.2251\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 0s 520us/sample - loss: 0.3741 - val_loss: 0.2215\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 0s 413us/sample - loss: 0.3701 - val_loss: 0.2179\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 0s 564us/sample - loss: 0.3957 - val_loss: 0.2142\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 0s 524us/sample - loss: 0.3725 - val_loss: 0.2108\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 0s 532us/sample - loss: 0.3273 - val_loss: 0.2077\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 0s 537us/sample - loss: 0.3411 - val_loss: 0.2049\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 0s 576us/sample - loss: 0.3611 - val_loss: 0.2022\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 0s 506us/sample - loss: 0.3384 - val_loss: 0.1999\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 0s 464us/sample - loss: 0.3312 - val_loss: 0.1981\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 0s 668us/sample - loss: 0.3375 - val_loss: 0.1964\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 0s 555us/sample - loss: 0.3564 - val_loss: 0.1946\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 0s 524us/sample - loss: 0.3316 - val_loss: 0.1930\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 0s 540us/sample - loss: 0.3178 - val_loss: 0.1914\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 0s 516us/sample - loss: 0.3209 - val_loss: 0.1897\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 0s 503us/sample - loss: 0.3319 - val_loss: 0.1879\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 0s 485us/sample - loss: 0.3054 - val_loss: 0.1863\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 0s 476us/sample - loss: 0.3461 - val_loss: 0.1847\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 0s 415us/sample - loss: 0.3230 - val_loss: 0.1828\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 0s 466us/sample - loss: 0.2862 - val_loss: 0.1810\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 0s 437us/sample - loss: 0.3073 - val_loss: 0.1792\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 0s 472us/sample - loss: 0.3273 - val_loss: 0.1775\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 0s 497us/sample - loss: 0.3061 - val_loss: 0.1758\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 0s 434us/sample - loss: 0.2874 - val_loss: 0.1743\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 0s 465us/sample - loss: 0.2783 - val_loss: 0.1732\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 0s 528us/sample - loss: 0.2733 - val_loss: 0.1721\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 0s 528us/sample - loss: 0.2900 - val_loss: 0.1712\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 0s 510us/sample - loss: 0.2832 - val_loss: 0.1703\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 0s 544us/sample - loss: 0.2985 - val_loss: 0.1693\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 0s 488us/sample - loss: 0.3195 - val_loss: 0.1687\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 0s 357us/sample - loss: 0.2937 - val_loss: 0.1681\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 0s 411us/sample - loss: 0.2865 - val_loss: 0.1674\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 0s 442us/sample - loss: 0.2848 - val_loss: 0.1668\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 0s 470us/sample - loss: 0.2860 - val_loss: 0.1664\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 0s 404us/sample - loss: 0.2621 - val_loss: 0.1660\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 0s 438us/sample - loss: 0.2642 - val_loss: 0.1656\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 0s 371us/sample - loss: 0.2775 - val_loss: 0.1652\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 0s 427us/sample - loss: 0.2575 - val_loss: 0.1648\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 0s 371us/sample - loss: 0.2540 - val_loss: 0.1645\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 0s 436us/sample - loss: 0.2738 - val_loss: 0.1643\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 0s 408us/sample - loss: 0.2732 - val_loss: 0.1639\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 0s 425us/sample - loss: 0.2825 - val_loss: 0.1632\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 0s 368us/sample - loss: 0.2582 - val_loss: 0.1626\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 0s 425us/sample - loss: 0.2720 - val_loss: 0.1618\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 0s 416us/sample - loss: 0.2679 - val_loss: 0.1612\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 0s 417us/sample - loss: 0.2663 - val_loss: 0.1606\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 0s 402us/sample - loss: 0.2362 - val_loss: 0.1600\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 0s 376us/sample - loss: 0.2507 - val_loss: 0.1594\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 0s 418us/sample - loss: 0.2596 - val_loss: 0.1588\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 0s 399us/sample - loss: 0.2499 - val_loss: 0.1582\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 0s 423us/sample - loss: 0.2365 - val_loss: 0.1577\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 410us/sample - loss: 0.2556 - val_loss: 0.1573\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 0s 386us/sample - loss: 0.2432 - val_loss: 0.1569\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 0s 405us/sample - loss: 0.2334 - val_loss: 0.1564\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 0s 417us/sample - loss: 0.2554 - val_loss: 0.1560\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 0s 396us/sample - loss: 0.2580 - val_loss: 0.1554\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 0s 406us/sample - loss: 0.2475 - val_loss: 0.1546\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 0s 398us/sample - loss: 0.2554 - val_loss: 0.1540\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 0s 383us/sample - loss: 0.2467 - val_loss: 0.1534\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 0s 438us/sample - loss: 0.2511 - val_loss: 0.1529\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 0s 370us/sample - loss: 0.2485 - val_loss: 0.1524\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 0s 440us/sample - loss: 0.2395 - val_loss: 0.1521\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 0s 401us/sample - loss: 0.2429 - val_loss: 0.1518\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 0s 355us/sample - loss: 0.2421 - val_loss: 0.1515\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 0s 414us/sample - loss: 0.2270 - val_loss: 0.1511\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 0s 403us/sample - loss: 0.2397 - val_loss: 0.1506\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 0s 375us/sample - loss: 0.2425 - val_loss: 0.1503\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 0s 422us/sample - loss: 0.2426 - val_loss: 0.1500\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 0s 411us/sample - loss: 0.2287 - val_loss: 0.1498\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 0s 415us/sample - loss: 0.2243 - val_loss: 0.1497\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 0s 413us/sample - loss: 0.2407 - val_loss: 0.1497\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 0s 401us/sample - loss: 0.2194 - val_loss: 0.1496\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 0s 381us/sample - loss: 0.1943 - val_loss: 0.1495\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 0s 438us/sample - loss: 0.2258 - val_loss: 0.1492\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 0s 365us/sample - loss: 0.2371 - val_loss: 0.1488\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 0s 378us/sample - loss: 0.2276 - val_loss: 0.1483\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 0s 442us/sample - loss: 0.2326 - val_loss: 0.1477\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 0s 446us/sample - loss: 0.2178 - val_loss: 0.1470\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 0s 371us/sample - loss: 0.2314 - val_loss: 0.1466\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 0s 367us/sample - loss: 0.2162 - val_loss: 0.1462\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 0s 439us/sample - loss: 0.2048 - val_loss: 0.1457\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 0s 413us/sample - loss: 0.2107 - val_loss: 0.1451\n"
     ]
    }
   ],
   "source": [
    "deepRegression = True\n",
    "\n",
    "users = np.array(users)\n",
    "games = np.array(games)\n",
    "rewards = np.array(rewards)\n",
    "\n",
    "if deepRegression:\n",
    "    features = []\n",
    "    for i in range(len(users)):\n",
    "        features.append(env.get_feature_vector(users[i], games[i]))\n",
    "    features = np.float64(features)\n",
    "    agent = EmbeddingAgent([users, games, features], rewards, deepRegression=deepRegression)\n",
    "else:\n",
    "    agent = EmbeddingAgent([users, games], rewards, deepRegression=deepRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_env = deepcopy(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_iteration = 100\n",
    "nb_exp = 100\n",
    "#---------------#\n",
    "regret = np.zeros(nb_exp)\n",
    "cum_regret = np.zeros((nb_exp, nb_iteration))\n",
    "\n",
    "for t in range(nb_exp):\n",
    "    env = deepcopy(prev_env)\n",
    "    env.reset_seed()\n",
    "    regrets = np.zeros(nb_iteration)\n",
    "    for i in range(nb_iteration):\n",
    "        user, available_games, optimal_reward, finish = env.step()\n",
    "        if finish:\n",
    "            print(\"Maybe too many trial try to reduce and reset the environment\")\n",
    "            break\n",
    "        choosen_game = agent.act(user, available_games)\n",
    "        reward = env.update(user, choosen_game)\n",
    "        regrets[i] = optimal_reward - reward\n",
    "        print(\"user = {}, available games = {}, choosen_game = {}\".format(user,available_games,choosen_game))\n",
    "        print(\"reward = {}\\n\".format(reward))\n",
    "    cum_regret[t] = np.cumsum(regrets)\n",
    "    regret[t] = np.sum(regrets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cum_regret.mean(axis=0), color='blue')\n",
    "plt.plot(np.quantile(cum_regret, 0.05,axis=0), color='grey', alpha=0.5)\n",
    "plt.plot(np.quantile(cum_regret, 0.95,axis=0), color='grey', alpha=0.5)\n",
    "plt.title('Mean regret: {:.2f}'.format(regret.mean()))\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('regret')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
