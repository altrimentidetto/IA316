{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steam (Environment - Agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "# Basic import\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import copy, deepcopy\n",
    "from scipy.stats import invgamma, gamma\n",
    "from scipy.stats import t as student\n",
    "import pdb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout, Dot, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \"\"\" \n",
    "    Contextual Multi-Armed Bandit environment\n",
    "    \"\"\"\n",
    "    def __init__(self, nb_films, nb_users, \n",
    "                 context_size = 2,\n",
    "                 displayed_users_embedding_size = 2, \n",
    "                 displayed_games_embedding_size = 2, \n",
    "                 noise_size = 3,\n",
    "                 seed=None):\n",
    "        self._nb_games = nb_games\n",
    "        self._nb_users = nb_users\n",
    "        self._p = context_size # size of user, size of game\n",
    "        self._displayed_users_embedding_size = displayed_users_embedding_size\n",
    "        self._displayed_games_embedding_size = displayed_games_embedding_size\n",
    "        self._noise_size = noise_size\n",
    "        self._rng = np.random.RandomState(seed)\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\" Play an action \"\"\"\n",
    "        user = self._rng.randint(0, self._nb_users)\n",
    "        available_games = np.where(self._available_games[user] == 1)[0]\n",
    "        return user, available_games\n",
    "    \n",
    "    def update(self, user, game):\n",
    "        reward = self._reward_matrix[user, game]\n",
    "        self._available_games[user, game] = 0\n",
    "        return reward\n",
    "    \n",
    "    def reset(self):\n",
    "        #self._games = self._rng.uniform(size=(nb_games, context_size))\n",
    "        #self._users = self._rng.uniform(size=(nb_users, context_size))\n",
    "        #-------------------------------------------------------#\n",
    "        self.user_mean = np.ones(self._p)\n",
    "        self.user_var = np.ones(self._p)\n",
    "        self.game_mean = np.ones(self._p)\n",
    "        self.game_var = np.ones(self._p)\n",
    "        self._users = self._rng.normal(loc=self.user_mean,\n",
    "                                                scale=self.user_var,\n",
    "                                                size=(self._nb_users, self._p))\n",
    "        self._games = self._rng.normal(loc=self.game_mean,\n",
    "                                                scale=self.game_var,\n",
    "                                                size=(self._nb_games, self._p))\n",
    "        #-------------------------------------------------------#\n",
    "        self._reward_matrix = np.zeros((nb_users, nb_games))\n",
    "        for i in range(self._reward_matrix.shape[0]):\n",
    "            for j in range(self._reward_matrix.shape[1]):\n",
    "                # reward = np.linalg.norm(self._games[j] - self._users[i], ord=2)\n",
    "                reward = self._games[j].dot(self._users[i])\n",
    "                self._reward_matrix[i, j] = reward\n",
    "        self._reward_matrix = ((self._reward_matrix - np.min(self._reward_matrix)) / np.max(self._reward_matrix) * 4).astype(int) + 1\n",
    "        self._available_games = np.ones((nb_users, nb_games))\n",
    "        self._available_films = np.ones((nb_users, nb_games))\n",
    "        users = deepcopy(self._users)\n",
    "        return users\n",
    "\n",
    "    def get_feature_vector(self, user, game):\n",
    "        user_embedding = self._users[user]\n",
    "        game_embedding = self._games[game]\n",
    "        if self._displayed_users_embedding_size + self._displayed_games_embedding_size > 0:\n",
    "            variables = np.array([user_embedding[:self._displayed_users_embedding_size],\n",
    "                                  game_embedding[:self._displayed_games_embedding_size]])\n",
    "\n",
    "            if self._noise_size > 0:\n",
    "                noise = self._rng.normal(loc=np.ones(self._noise_size),\n",
    "                                         scale=np.ones(self._noise_size),\n",
    "                                         size=self._noise_size)\n",
    "                variables = np.append(variables, noise)\n",
    "            return variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "    \"\"\" \n",
    "    Random agent\n",
    "    \"\"\"\n",
    "    def __init__(self, seed = None):\n",
    "        self._rng = np.random.RandomState(seed)\n",
    "    \n",
    "    def act(self, available_games):\n",
    "        action = self._rng.choice(available_games)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic parameter\n",
    "nb_users = 30 #number of users in the context\n",
    "nb_games = 10 #number of games in the context\n",
    "context_size = 2 #number of different film categories = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.48498184,  1.26196845],\n",
       "       [ 1.93963171,  0.80235644],\n",
       "       [ 0.71129992,  1.40236516],\n",
       "       [ 1.2675628 ,  1.50936377],\n",
       "       [ 1.44465119,  2.40601401],\n",
       "       [ 0.00538904,  1.07947062],\n",
       "       [ 1.44188963,  1.6729676 ],\n",
       "       [ 0.08965077,  0.80236926],\n",
       "       [ 1.73706095,  2.13451562],\n",
       "       [ 1.20991524,  1.20128777],\n",
       "       [ 2.40012652,  0.97874821],\n",
       "       [ 0.37882481,  0.5025776 ],\n",
       "       [ 0.60090051,  1.64231227],\n",
       "       [ 1.57053191, -0.52238166],\n",
       "       [-1.22937729,  1.41049177],\n",
       "       [ 1.90333509, -0.01256267],\n",
       "       [-0.84473841,  1.81383781],\n",
       "       [ 0.14327327,  2.39216124],\n",
       "       [ 1.28667635,  1.00436545],\n",
       "       [-0.2447395 ,  2.36752408],\n",
       "       [ 0.52334678, -1.09209878],\n",
       "       [ 2.72619731,  0.35124098],\n",
       "       [ 0.82016351,  1.84104755],\n",
       "       [-0.32666989,  0.99943449],\n",
       "       [ 1.37461262, -0.94690252],\n",
       "       [ 2.54900226,  0.53197812],\n",
       "       [ 0.09236578,  0.22169957],\n",
       "       [-0.08830567,  0.92643129],\n",
       "       [ 3.53475691,  1.65387353],\n",
       "       [ 0.36638349,  0.13105982]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the environment\n",
    "env = Environment(nb_games,nb_users,context_size,2020)\n",
    "env.reset() #reset and initilize the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the agent\n",
    "agent = RandomAgent(2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the experiment and generate some historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating matrix: \n",
      " [[0. 0. 0. 0. 0. 0. 3. 3. 0. 0.]\n",
      " [0. 4. 2. 0. 3. 3. 0. 3. 0. 0.]\n",
      " [3. 4. 0. 4. 3. 0. 3. 3. 3. 3.]\n",
      " [3. 4. 0. 0. 3. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 6. 0. 3. 0. 3. 0. 0.]\n",
      " [2. 0. 0. 4. 0. 0. 0. 0. 0. 0.]\n",
      " [3. 4. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 3. 0. 3. 2. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 3.]\n",
      " [2. 4. 3. 0. 3. 3. 3. 0. 4. 3.]\n",
      " [2. 0. 2. 5. 3. 0. 3. 0. 0. 0.]\n",
      " [0. 0. 0. 3. 3. 0. 3. 0. 3. 2.]\n",
      " [3. 0. 3. 0. 0. 0. 0. 3. 0. 0.]\n",
      " [2. 0. 0. 0. 0. 0. 0. 2. 4. 0.]\n",
      " [0. 0. 4. 3. 0. 0. 3. 0. 0. 0.]\n",
      " [0. 0. 2. 0. 0. 0. 3. 0. 5. 0.]\n",
      " [0. 0. 0. 4. 0. 0. 3. 0. 0. 0.]\n",
      " [3. 0. 0. 0. 0. 0. 0. 3. 2. 0.]\n",
      " [0. 0. 0. 4. 0. 0. 0. 0. 0. 3.]\n",
      " [0. 0. 0. 5. 0. 2. 0. 0. 0. 2.]\n",
      " [2. 0. 0. 0. 0. 0. 0. 0. 3. 0.]\n",
      " [0. 0. 0. 0. 3. 0. 3. 0. 0. 0.]\n",
      " [3. 4. 3. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 3. 0. 0. 3. 3. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 2. 0. 4. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 3. 3. 0. 3.]\n",
      " [0. 0. 3. 3. 0. 0. 2. 0. 0. 2.]\n",
      " [0. 3. 0. 3. 3. 2. 0. 0. 0. 2.]\n",
      " [2. 5. 0. 0. 0. 0. 4. 3. 0. 4.]\n",
      " [2. 0. 0. 0. 0. 0. 0. 0. 3. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Running several trials\n",
    "nb_iteration = 100 #how many trials\n",
    "rating_matrix = np.zeros((env._nb_users, env._nb_games))\n",
    "users = list()\n",
    "games = list()\n",
    "ratings = list()\n",
    "for i in range(nb_iteration):\n",
    "    user, available_games = env.step()\n",
    "    choosen_game = agent.act(available_games)\n",
    "    reward = env.update(user, choosen_game)\n",
    "    users.append(user)\n",
    "    games.append(choosen_game)\n",
    "    ratings.append(reward)\n",
    "    rating_matrix[user, choosen_game] = reward\n",
    "    '''\n",
    "    print(\"user = {}, recommended_games = {}, choosen_game = {}\".format(user,recommended_games,choosen_game))\n",
    "    print(\"reward = {}\\n\".format(reward))\n",
    "    '''\n",
    "    \n",
    "print(\"rating matrix: \\n\", str(rating_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(Model):\n",
    "    def __init__(self, embedding_size, max_user, max_game):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_embedding = Embedding(output_dim=embedding_size,\n",
    "                                        input_dim=max_user,\n",
    "                                        input_length=1,\n",
    "                                        name='user_embedding')\n",
    "        self.game_embedding = Embedding(output_dim=embedding_size,\n",
    "                                        input_dim=max_game,\n",
    "                                        input_length=1,\n",
    "                                        name='game_embedding')\n",
    "        \n",
    "        # The following two layers don't have parameters.\n",
    "        self.flatten = Flatten()\n",
    "        self.dot = Dot(axes=1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        user_inputs = inputs[0]\n",
    "        game_inputs = inputs[1]\n",
    "        \n",
    "        user_vecs = self.flatten(self.user_embedding(user_inputs))\n",
    "        game_vecs = self.flatten(self.game_embedding(game_inputs))\n",
    "        \n",
    "        y = self.dot([user_vecs, game_vecs])\n",
    "        return y\n",
    "\n",
    "model = RegressionModel(64, nb_users, nb_games)\n",
    "model.compile(optimizer=\"adam\", loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 0s 521us/sample - loss: 3.0442 - val_loss: 3.1995\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 0s 473us/sample - loss: 3.0419 - val_loss: 3.1993\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 0s 458us/sample - loss: 3.0399 - val_loss: 3.1992\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 0s 333us/sample - loss: 3.0378 - val_loss: 3.1990\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 0s 422us/sample - loss: 3.0358 - val_loss: 3.1988\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 0s 418us/sample - loss: 3.0337 - val_loss: 3.1985\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 0s 425us/sample - loss: 3.0315 - val_loss: 3.1982\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 0s 403us/sample - loss: 3.0292 - val_loss: 3.1978\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 0s 352us/sample - loss: 3.0268 - val_loss: 3.1973\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 0s 461us/sample - loss: 3.0242 - val_loss: 3.1967\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 0s 533us/sample - loss: 3.0215 - val_loss: 3.1959\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 0s 536us/sample - loss: 3.0185 - val_loss: 3.1951\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 0s 474us/sample - loss: 3.0153 - val_loss: 3.1941\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 0s 480us/sample - loss: 3.0119 - val_loss: 3.1930\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 0s 495us/sample - loss: 3.0082 - val_loss: 3.1917\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 0s 482us/sample - loss: 3.0042 - val_loss: 3.1902\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 0s 546us/sample - loss: 2.9999 - val_loss: 3.1884\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 0s 436us/sample - loss: 2.9953 - val_loss: 3.1865\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 0s 441us/sample - loss: 2.9902 - val_loss: 3.1843\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 0s 468us/sample - loss: 2.9849 - val_loss: 3.1818\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 0s 385us/sample - loss: 2.9791 - val_loss: 3.1791\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 0s 412us/sample - loss: 2.9729 - val_loss: 3.1762\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 0s 501us/sample - loss: 2.9662 - val_loss: 3.1728\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 0s 405us/sample - loss: 2.9591 - val_loss: 3.1692\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 0s 409us/sample - loss: 2.9514 - val_loss: 3.1651\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 0s 450us/sample - loss: 2.9432 - val_loss: 3.1607\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 0s 407us/sample - loss: 2.9345 - val_loss: 3.1559\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 0s 424us/sample - loss: 2.9252 - val_loss: 3.1508\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 0s 412us/sample - loss: 2.9153 - val_loss: 3.1452\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 0s 474us/sample - loss: 2.9048 - val_loss: 3.1391\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 0s 450us/sample - loss: 2.8936 - val_loss: 3.1327\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 0s 468us/sample - loss: 2.8818 - val_loss: 3.1258\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 0s 317us/sample - loss: 2.8694 - val_loss: 3.1184\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 0s 420us/sample - loss: 2.8563 - val_loss: 3.1104\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 0s 454us/sample - loss: 2.8425 - val_loss: 3.1020\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 0s 442us/sample - loss: 2.8280 - val_loss: 3.0930\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 0s 452us/sample - loss: 2.8126 - val_loss: 3.0833\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 0s 418us/sample - loss: 2.7967 - val_loss: 3.0731\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 0s 509us/sample - loss: 2.7801 - val_loss: 3.0622\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 0s 433us/sample - loss: 2.7626 - val_loss: 3.0508\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 0s 451us/sample - loss: 2.7445 - val_loss: 3.0389\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 0s 535us/sample - loss: 2.7253 - val_loss: 3.0264\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 0s 499us/sample - loss: 2.7054 - val_loss: 3.0132\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 0s 469us/sample - loss: 2.6848 - val_loss: 2.9994\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 0s 506us/sample - loss: 2.6632 - val_loss: 2.9850\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 0s 511us/sample - loss: 2.6408 - val_loss: 2.9698\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 0s 512us/sample - loss: 2.6176 - val_loss: 2.9541\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 0s 468us/sample - loss: 2.5935 - val_loss: 2.9377\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 0s 503us/sample - loss: 2.5684 - val_loss: 2.9207\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 0s 450us/sample - loss: 2.5426 - val_loss: 2.9030\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 0s 419us/sample - loss: 2.5157 - val_loss: 2.8848\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 0s 413us/sample - loss: 2.4881 - val_loss: 2.8657\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 0s 438us/sample - loss: 2.4593 - val_loss: 2.8459\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 0s 468us/sample - loss: 2.4297 - val_loss: 2.8254\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 0s 465us/sample - loss: 2.3992 - val_loss: 2.8044\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 0s 352us/sample - loss: 2.3677 - val_loss: 2.7829\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 0s 378us/sample - loss: 2.3352 - val_loss: 2.7606\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 0s 371us/sample - loss: 2.3017 - val_loss: 2.7378\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 0s 381us/sample - loss: 2.2674 - val_loss: 2.7145\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 0s 399us/sample - loss: 2.2320 - val_loss: 2.6903\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 0s 390us/sample - loss: 2.1957 - val_loss: 2.6651\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 0s 368us/sample - loss: 2.1582 - val_loss: 2.6389\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 0s 369us/sample - loss: 2.1198 - val_loss: 2.6122\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 0s 374us/sample - loss: 2.0805 - val_loss: 2.5844\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 0s 356us/sample - loss: 2.0401 - val_loss: 2.5554\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 0s 397us/sample - loss: 1.9988 - val_loss: 2.5255\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 0s 397us/sample - loss: 1.9565 - val_loss: 2.4950\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 0s 392us/sample - loss: 1.9129 - val_loss: 2.4640\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 0s 395us/sample - loss: 1.8686 - val_loss: 2.4322\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 0s 369us/sample - loss: 1.8231 - val_loss: 2.3997\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 0s 371us/sample - loss: 1.7768 - val_loss: 2.3666\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 0s 359us/sample - loss: 1.7291 - val_loss: 2.3330\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 0s 379us/sample - loss: 1.6807 - val_loss: 2.2986\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 0s 369us/sample - loss: 1.6312 - val_loss: 2.2635\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 0s 438us/sample - loss: 1.5809 - val_loss: 2.2278\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 0s 471us/sample - loss: 1.5297 - val_loss: 2.1908\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 0s 491us/sample - loss: 1.4769 - val_loss: 2.1526\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 0s 484us/sample - loss: 1.4239 - val_loss: 2.1138\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 394us/sample - loss: 1.3695 - val_loss: 2.0745\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 0s 404us/sample - loss: 1.3172 - val_loss: 2.0343\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 0s 399us/sample - loss: 1.2632 - val_loss: 1.9934\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 0s 383us/sample - loss: 1.2109 - val_loss: 1.9521\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 0s 388us/sample - loss: 1.1614 - val_loss: 1.9099\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 0s 348us/sample - loss: 1.1136 - val_loss: 1.8675\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 0s 344us/sample - loss: 1.0710 - val_loss: 1.8259\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 0s 367us/sample - loss: 1.0304 - val_loss: 1.7849\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 0s 514us/sample - loss: 0.9928 - val_loss: 1.7441\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 0s 488us/sample - loss: 0.9524 - val_loss: 1.7036\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 0s 479us/sample - loss: 0.9160 - val_loss: 1.6628\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 0s 503us/sample - loss: 0.8786 - val_loss: 1.6232\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 0s 397us/sample - loss: 0.8424 - val_loss: 1.5851\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 0s 348us/sample - loss: 0.8049 - val_loss: 1.5470\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 0s 377us/sample - loss: 0.7698 - val_loss: 1.5091\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 0s 366us/sample - loss: 0.7328 - val_loss: 1.4720\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 0s 345us/sample - loss: 0.6953 - val_loss: 1.4355\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 0s 377us/sample - loss: 0.6590 - val_loss: 1.3995\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 0s 467us/sample - loss: 0.6222 - val_loss: 1.3642\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 0s 519us/sample - loss: 0.5921 - val_loss: 1.3306\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 0s 526us/sample - loss: 0.5672 - val_loss: 1.2995\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 0s 528us/sample - loss: 0.5450 - val_loss: 1.2690\n"
     ]
    }
   ],
   "source": [
    "users = np.array(users)\n",
    "games = np.array(games)\n",
    "ratings = np.array(ratings)\n",
    "\n",
    "history = model.fit([users, games], ratings,\n",
    "                    batch_size=64, epochs=100, validation_split=0.1,\n",
    "                    shuffle=True)\n",
    "\n",
    "embeddings = model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(x, y):\n",
    "    dot = np.dot(x, y)\n",
    "    norm_x = np.linalg.norm(x)\n",
    "    norm_y = np.linalg.norm(y)\n",
    "    cos = dot / (norm_x * norm_y)\n",
    "    return cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingAgent:\n",
    "    \"\"\" \n",
    "    Embedding Agent\n",
    "    \"\"\"\n",
    "    def __init__(self, user_embeddings, game_embeddings):\n",
    "        self._game_embeddings = game_embeddings\n",
    "        self._user_embeddings = user_embeddings\n",
    "    \n",
    "    def act(self, user, available_games):\n",
    "        user_embedding = self._user_embeddings[user]\n",
    "        dot_products = self._game_embeddings @ user_embedding\n",
    "        user_embedding_norm = np.linalg.norm(user_embedding)\n",
    "        all_item_norms = np.linalg.norm(self._game_embeddings, axis=1)\n",
    "        norm_products = user_embedding_norm * all_item_norms\n",
    "        sims = dot_products / (norm_products)\n",
    "        sims = np.argsort(sims)[::-1]\n",
    "        mask = np.in1d(sims, available_games)\n",
    "        sims = sims[mask]\n",
    "        return sims[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying the embedding agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user = 9, available games = [3 7], choosen_game = 7\n",
      "reward = 3\n",
      "\n",
      "user = 23, available games = [0 1 2 4 5 8 9], choosen_game = 9\n",
      "reward = 2\n",
      "\n",
      "user = 7, available games = [0 1 3 6 7 8 9], choosen_game = 1\n",
      "reward = 3\n",
      "\n",
      "user = 13, available games = [1 2 3 4 5 6 9], choosen_game = 1\n",
      "reward = 3\n",
      "\n",
      "user = 4, available games = [0 1 2 4 6 8 9], choosen_game = 9\n",
      "reward = 3\n",
      "\n",
      "user = 12, available games = [1 3 4 5 6 8 9], choosen_game = 8\n",
      "reward = 3\n",
      "\n",
      "user = 10, available games = [1 5 7 8 9], choosen_game = 9\n",
      "reward = 3\n",
      "\n",
      "user = 4, available games = [0 1 2 4 6 8], choosen_game = 4\n",
      "reward = 3\n",
      "\n",
      "user = 23, available games = [0 1 2 4 5 8], choosen_game = 4\n",
      "reward = 2\n",
      "\n",
      "user = 16, available games = [0 1 2 4 5 7 8 9], choosen_game = 9\n",
      "reward = 2\n",
      "\n",
      "user = 26, available games = [0 1 4 5 7 8], choosen_game = 4\n",
      "reward = 2\n",
      "\n",
      "user = 5, available games = [1 2 4 5 6 7 8 9], choosen_game = 7\n",
      "reward = 3\n",
      "\n",
      "user = 26, available games = [0 1 5 7 8], choosen_game = 7\n",
      "reward = 2\n",
      "\n",
      "user = 26, available games = [0 1 5 8], choosen_game = 8\n",
      "reward = 2\n",
      "\n",
      "user = 20, available games = [1 2 3 4 5 6 7 9], choosen_game = 1\n",
      "reward = 2\n",
      "\n",
      "user = 3, available games = [2 3 5 6 7 8 9], choosen_game = 8\n",
      "reward = 4\n",
      "\n",
      "user = 8, available games = [0 1 2 3 4 5 6 7 8], choosen_game = 6\n",
      "reward = 4\n",
      "\n",
      "user = 28, available games = [2 3 4 5 8], choosen_game = 4\n",
      "reward = 4\n",
      "\n",
      "user = 23, available games = [0 1 2 5 8], choosen_game = 8\n",
      "reward = 2\n",
      "\n",
      "user = 25, available games = [0 1 2 3 4 5 8], choosen_game = 3\n",
      "reward = 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating the agent\n",
    "agent = EmbeddingAgent(embeddings[0], embeddings[1])\n",
    "\n",
    "# Running several trials\n",
    "nb_iteration = 20 #how many trials\n",
    "for i in range(nb_iteration):\n",
    "    user, available_games = env.step()\n",
    "    choosen_game = agent.act(user, available_games)\n",
    "    reward = env.update(user, choosen_game)\n",
    "    rating_matrix[user, choosen_game] = reward\n",
    "    print(\"user = {}, available games = {}, choosen_game = {}\".format(user,available_games,choosen_game))\n",
    "    print(\"reward = {}\\n\".format(reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepRegressionModel(Model):\n",
    "\n",
    "    def __init__(self, embedding_size, max_user, max_game):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_embedding = Embedding(output_dim=embedding_size,\n",
    "                                        input_dim=max_user,\n",
    "                                        input_length=1,\n",
    "                                        name='user_embedding')\n",
    "        self.game_embedding = Embedding(output_dim=embedding_size,\n",
    "                                        input_dim=max_game,\n",
    "                                        input_length=1,\n",
    "                                        name='game_embedding')\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.concat = Concatenate()\n",
    "        \n",
    "        self.dense1 = Dense(16, activation=\"relu\")\n",
    "        self.dense2 = Dense(8, activation=\"relu\")\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        user_inputs = inputs[0]\n",
    "        game_inputs = inputs[1]\n",
    "        feature_inputs = inputs[2]\n",
    "        print(feature_inputs)\n",
    "\n",
    "        \n",
    "        user_vecs = self.flatten(self.user_embedding(user_inputs))\n",
    "        game_vecs = self.flatten(self.game_embedding(game_inputs))\n",
    "        \n",
    "        # input_vecs = self.concat([user_vecs, game_vecs, self.flatten(feature_inputs)])\n",
    "        input_vecs = self.concat([user_vecs, game_vecs])\n",
    "        \n",
    "        y = self.dense1(input_vecs)\n",
    "        y = self.dense2(y)\n",
    "        \n",
    "        return y\n",
    "        \n",
    "model = DeepRegressionModel(64, nb_users, nb_games)\n",
    "model.compile(optimizer=\"adam\", loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_3:0\", shape=(None, 7), dtype=float32)\n",
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "Tensor(\"Cast:0\", shape=(None, 7), dtype=float32)\n",
      "Tensor(\"Cast:0\", shape=(None, 7), dtype=float32)\n",
      "64/90 [====================>.........] - ETA: 0s - loss: 2.2000Tensor(\"Cast:0\", shape=(None, 7), dtype=float32)\n",
      "90/90 [==============================] - 1s 6ms/sample - loss: 2.2155 - val_loss: 1.6526\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 0s 115us/sample - loss: 2.1973 - val_loss: 1.6333\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 0s 180us/sample - loss: 2.1791 - val_loss: 1.6140\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 0s 202us/sample - loss: 2.1615 - val_loss: 1.5945\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 0s 213us/sample - loss: 2.1436 - val_loss: 1.5754\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 0s 193us/sample - loss: 2.1256 - val_loss: 1.5560\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 0s 204us/sample - loss: 2.1078 - val_loss: 1.5365\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 0s 203us/sample - loss: 2.0895 - val_loss: 1.5173\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 0s 218us/sample - loss: 2.0709 - val_loss: 1.4976\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 0s 220us/sample - loss: 2.0519 - val_loss: 1.4772\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 0s 228us/sample - loss: 2.0323 - val_loss: 1.4563\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 0s 177us/sample - loss: 2.0122 - val_loss: 1.4344\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 0s 193us/sample - loss: 1.9911 - val_loss: 1.4119\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 0s 187us/sample - loss: 1.9693 - val_loss: 1.3887\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 0s 223us/sample - loss: 1.9465 - val_loss: 1.3650\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 0s 206us/sample - loss: 1.9231 - val_loss: 1.3404\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 0s 196us/sample - loss: 1.8985 - val_loss: 1.3152\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 0s 210us/sample - loss: 1.8733 - val_loss: 1.2896\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 0s 210us/sample - loss: 1.8469 - val_loss: 1.2634\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 0s 202us/sample - loss: 1.8196 - val_loss: 1.2366\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 0s 220us/sample - loss: 1.7912 - val_loss: 1.2090\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 0s 219us/sample - loss: 1.7618 - val_loss: 1.1801\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 0s 241us/sample - loss: 1.7311 - val_loss: 1.1502\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 0s 202us/sample - loss: 1.6997 - val_loss: 1.1192\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 0s 184us/sample - loss: 1.6671 - val_loss: 1.0883\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 0s 210us/sample - loss: 1.6343 - val_loss: 1.0575\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 0s 234us/sample - loss: 1.6010 - val_loss: 1.0275\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 0s 235us/sample - loss: 1.5681 - val_loss: 0.9977\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 0s 220us/sample - loss: 1.5356 - val_loss: 0.9674\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 0s 256us/sample - loss: 1.5045 - val_loss: 0.9387\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 0s 221us/sample - loss: 1.4744 - val_loss: 0.9116\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 0s 220us/sample - loss: 1.4464 - val_loss: 0.8862\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 0s 190us/sample - loss: 1.4204 - val_loss: 0.8632\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 0s 218us/sample - loss: 1.3967 - val_loss: 0.8425\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 0s 254us/sample - loss: 1.3754 - val_loss: 0.8241\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 0s 203us/sample - loss: 1.3566 - val_loss: 0.8079\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 0s 207us/sample - loss: 1.3397 - val_loss: 0.7939\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 0s 208us/sample - loss: 1.3250 - val_loss: 0.7817\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 0s 243us/sample - loss: 1.3122 - val_loss: 0.7712\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 0s 204us/sample - loss: 1.3012 - val_loss: 0.7622\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 0s 199us/sample - loss: 1.2917 - val_loss: 0.7545\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 0s 215us/sample - loss: 1.2835 - val_loss: 0.7480\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 0s 196us/sample - loss: 1.2764 - val_loss: 0.7425\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 0s 225us/sample - loss: 1.2704 - val_loss: 0.7377\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 0s 224us/sample - loss: 1.2652 - val_loss: 0.7337\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 0s 207us/sample - loss: 1.2608 - val_loss: 0.7302\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 0s 209us/sample - loss: 1.2569 - val_loss: 0.7272\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 0s 194us/sample - loss: 1.2536 - val_loss: 0.7247\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 0s 216us/sample - loss: 1.2508 - val_loss: 0.7225\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 0s 201us/sample - loss: 1.2483 - val_loss: 0.7206\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 0s 212us/sample - loss: 1.2462 - val_loss: 0.7189\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 0s 161us/sample - loss: 1.2443 - val_loss: 0.7174\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 0s 130us/sample - loss: 1.2426 - val_loss: 0.7161\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 0s 203us/sample - loss: 1.2411 - val_loss: 0.7150\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 0s 166us/sample - loss: 1.2399 - val_loss: 0.7140\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 0s 189us/sample - loss: 1.2387 - val_loss: 0.7131\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 0s 165us/sample - loss: 1.2377 - val_loss: 0.7123\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 0s 165us/sample - loss: 1.2368 - val_loss: 0.7115\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 0s 172us/sample - loss: 1.2359 - val_loss: 0.7109\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 0s 163us/sample - loss: 1.2352 - val_loss: 0.7103\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 0s 185us/sample - loss: 1.2345 - val_loss: 0.7097\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 0s 175us/sample - loss: 1.2339 - val_loss: 0.7092\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 0s 173us/sample - loss: 1.2333 - val_loss: 0.7088\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 0s 168us/sample - loss: 1.2328 - val_loss: 0.7084\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 0s 206us/sample - loss: 1.2323 - val_loss: 0.7080\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 0s 167us/sample - loss: 1.2318 - val_loss: 0.7077\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 0s 170us/sample - loss: 1.2314 - val_loss: 0.7073\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 0s 180us/sample - loss: 1.2311 - val_loss: 0.7070\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 0s 180us/sample - loss: 1.2307 - val_loss: 0.7068\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 0s 180us/sample - loss: 1.2304 - val_loss: 0.7065\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 0s 178us/sample - loss: 1.2301 - val_loss: 0.7062\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 0s 178us/sample - loss: 1.2298 - val_loss: 0.7060\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 0s 172us/sample - loss: 1.2295 - val_loss: 0.7058\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 0s 175us/sample - loss: 1.2292 - val_loss: 0.7056\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 0s 185us/sample - loss: 1.2290 - val_loss: 0.7054\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 0s 179us/sample - loss: 1.2288 - val_loss: 0.7052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "90/90 [==============================] - 0s 174us/sample - loss: 1.2286 - val_loss: 0.7050\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 0s 176us/sample - loss: 1.2284 - val_loss: 0.7049\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 0s 157us/sample - loss: 1.2282 - val_loss: 0.7047\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 0s 165us/sample - loss: 1.2280 - val_loss: 0.7046\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 0s 170us/sample - loss: 1.2278 - val_loss: 0.7044\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 0s 166us/sample - loss: 1.2276 - val_loss: 0.7043\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 0s 167us/sample - loss: 1.2275 - val_loss: 0.7042\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 0s 171us/sample - loss: 1.2273 - val_loss: 0.7041\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 0s 171us/sample - loss: 1.2272 - val_loss: 0.7040\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 0s 179us/sample - loss: 1.2270 - val_loss: 0.7039\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 0s 187us/sample - loss: 1.2269 - val_loss: 0.7037\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 0s 163us/sample - loss: 1.2268 - val_loss: 0.7036\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 0s 168us/sample - loss: 1.2267 - val_loss: 0.7036\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 0s 167us/sample - loss: 1.2265 - val_loss: 0.7035\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 0s 147us/sample - loss: 1.2264 - val_loss: 0.7034\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 0s 127us/sample - loss: 1.2263 - val_loss: 0.7033\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 0s 158us/sample - loss: 1.2262 - val_loss: 0.7032\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 0s 162us/sample - loss: 1.2261 - val_loss: 0.7031\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 0s 173us/sample - loss: 1.2260 - val_loss: 0.7031\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 0s 164us/sample - loss: 1.2259 - val_loss: 0.7030\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 0s 171us/sample - loss: 1.2259 - val_loss: 0.7029\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 0s 172us/sample - loss: 1.2258 - val_loss: 0.7028\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 0s 167us/sample - loss: 1.2257 - val_loss: 0.7028\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 0s 167us/sample - loss: 1.2256 - val_loss: 0.7027\n"
     ]
    }
   ],
   "source": [
    "users = np.array(users)\n",
    "games = np.array(games)\n",
    "ratings = np.array(ratings)\n",
    "\n",
    "features = []\n",
    "for i in range(len(users)):\n",
    "    features.append(env.get_feature_vector(users[i], games[i]))\n",
    "features = np.float64(features)\n",
    "\n",
    "history = model.fit([users, games, features], ratings,\n",
    "                    batch_size=64, epochs=100, validation_split=0.1,\n",
    "                    shuffle=True)\n",
    "\n",
    "embeddings = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user = 25, available games = [0 1 2 5 7 8 9], choosen_game = 2\n",
      "reward = 1\n",
      "\n",
      "user = 19, available games = [0 1 2 3 4 5 6 7 8 9], choosen_game = 7\n",
      "reward = 2\n",
      "\n",
      "user = 10, available games = [2 4 7 8], choosen_game = 2\n",
      "reward = 1\n",
      "\n",
      "user = 13, available games = [0 1 2 3 4 5 7 8 9], choosen_game = 9\n",
      "reward = 3\n",
      "\n",
      "user = 1, available games = [4 5 6 8], choosen_game = 8\n",
      "reward = 2\n",
      "\n",
      "user = 18, available games = [1 2 3 4 5 6 7 8 9], choosen_game = 2\n",
      "reward = 3\n",
      "\n",
      "user = 19, available games = [0 1 2 3 4 5 6 8 9], choosen_game = 8\n",
      "reward = 2\n",
      "\n",
      "user = 19, available games = [0 1 2 3 4 5 6 9], choosen_game = 4\n",
      "reward = 1\n",
      "\n",
      "user = 2, available games = [2 4 8 9], choosen_game = 9\n",
      "reward = 2\n",
      "\n",
      "user = 8, available games = [0 1 4 7 8 9], choosen_game = 9\n",
      "reward = 2\n",
      "\n",
      "user = 6, available games = [0 1 2 3 4 6 9], choosen_game = 9\n",
      "reward = 4\n",
      "\n",
      "user = 4, available games = [0 4 8 9], choosen_game = 9\n",
      "reward = 2\n",
      "\n",
      "user = 10, available games = [4 7 8], choosen_game = 8\n",
      "reward = 1\n",
      "\n",
      "user = 15, available games = [0 2 4 7 9], choosen_game = 9\n",
      "reward = 3\n",
      "\n",
      "user = 6, available games = [0 1 2 3 4 6], choosen_game = 2\n",
      "reward = 2\n",
      "\n",
      "user = 3, available games = [0 2 4 5 6 7 9], choosen_game = 9\n",
      "reward = 2\n",
      "\n",
      "user = 24, available games = [0 1 2 3 6 7 8 9], choosen_game = 9\n",
      "reward = 2\n",
      "\n",
      "user = 3, available games = [0 2 4 5 6 7], choosen_game = 2\n",
      "reward = 1\n",
      "\n",
      "user = 13, available games = [0 1 2 3 4 5 7 8], choosen_game = 2\n",
      "reward = 3\n",
      "\n",
      "user = 11, available games = [0 1 2 3 5 6 7 8 9], choosen_game = 9\n",
      "reward = 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating the agent\n",
    "agent = EmbeddingAgent(embeddings[0], embeddings[1])\n",
    "\n",
    "# Running several trials\n",
    "nb_iteration = 20 #how many trials\n",
    "for i in range(nb_iteration):\n",
    "    user, available_games = env.step()\n",
    "    choosen_game = agent.act(user, available_games)\n",
    "    reward = env.update(user, choosen_game)\n",
    "    rating_matrix[user, choosen_game] = reward\n",
    "    print(\"user = {}, available games = {}, choosen_game = {}\".format(user,available_games,choosen_game))\n",
    "    print(\"reward = {}\\n\".format(reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
