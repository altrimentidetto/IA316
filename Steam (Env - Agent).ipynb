{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steam (Environment - Agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "# Basic import\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from scipy.stats import norm\n",
    "import pdb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout, Dot, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self, nb_films, nb_users, \n",
    "                 context_size = 2,\n",
    "                 displayed_users_embedding_size = 2, #used for the features vector\n",
    "                 displayed_games_embedding_size = 2, #used for the features vector\n",
    "                 noise_size = 3,\n",
    "                 rating_probability = 0.5,\n",
    "                 seed=None):     \n",
    "        self._rng = np.random.RandomState(seed)\n",
    "        self._rating_probability = rating_probability \n",
    "        #-------------------------------------------------------#\n",
    "        self._nb_games = nb_games\n",
    "        self._nb_users = nb_users\n",
    "        self._p = context_size # size of user, size of game\n",
    "        self._displayed_users_embedding_size = displayed_users_embedding_size\n",
    "        self._displayed_games_embedding_size = displayed_games_embedding_size\n",
    "        self._noise_size = noise_size\n",
    "        #-------------------------------------------------------\n",
    "        self.user_mean = np.ones(self._p)\n",
    "        self.user_var = np.ones(self._p)\n",
    "        self.game_mean = np.ones(self._p)\n",
    "        self.game_var = np.ones(self._p)\n",
    "        #-------------------------------------------------------#\n",
    "        self.finish = False # True = all games have been played\n",
    "    \n",
    "    def step(self):\n",
    "        if self.finish == True or self._available_games.sum() == 0: \n",
    "            # all players played all games\n",
    "            self.finish = True\n",
    "            print(\"All games played reset the environment\")\n",
    "            return 0, 0, self.finish\n",
    "        \n",
    "        user = self.get_next_user() # pick a user\n",
    "        available_games = np.where(self._available_games[user] == 1)[0]\n",
    "        optimal_reward = np.max(self._reward_matrix[user,available_games])\n",
    "        return user, available_games, optimal_reward, self.finish\n",
    "    \n",
    "    def get_next_user(self):\n",
    "        user = self._rng.randint(0, self._nb_users)\n",
    "        if np.sum(self._available_games[user,:]) > 0: \n",
    "            # still some games to play for user\n",
    "            return user\n",
    "        else: \n",
    "            # all games played for the current user\n",
    "            # find a random player between the ones who have some games left to play\n",
    "            row,cols = np.where(self._available_games == 1)\n",
    "            return self._rng.choice(row)\n",
    "    \n",
    "    def update(self, user, game):\n",
    "        # rate the game w/ probability = self._rating_probability\n",
    "        if np.random.binomial(1, self._rating_probability):\n",
    "            reward = self._reward_matrix[user, game]\n",
    "        else:\n",
    "            reward = 0\n",
    "        # in any case, store the time spent playing the game\n",
    "        # for simulation purposes, such playtime (always >= 0) is based on the similarity \n",
    "        # between the user profile and the game (i.e. like a reward) + some noise\n",
    "        playtime = np.searchsorted(self.z_cut_points, self._users[user].dot(self._games[game])) / 4\n",
    "        playtime += self._rng.normal(loc = 0.0, scale = 0.15)\n",
    "        playtime = np.clip(np.abs(playtime), 0, 1)\n",
    "        self._playtime[user, game] = playtime\n",
    "        \n",
    "        self._available_games[user, game] = 0\n",
    "        return reward, self._playtime[user, game]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.finish = False\n",
    "        self._users = self._rng.normal(loc=self.user_mean,\n",
    "                                                scale=self.user_var,\n",
    "                                                size=(self._nb_users, self._p))\n",
    "        self._games = self._rng.normal(loc=self.game_mean,\n",
    "                                                scale=self.game_var,\n",
    "                                                size=(self._nb_games, self._p))\n",
    "        \n",
    "        z_mean = self.user_mean.dot(self.game_mean)\n",
    "        z_var = self.user_var.dot(self.game_var) + self.user_var.dot(np.square(self.game_mean)) + \\\n",
    "                self.game_var.dot(np.square(self.user_mean))\n",
    "        z = norm(z_mean, np.sqrt(z_var))\n",
    "        self.z_cut_points = z.ppf([0.2, 0.4, 0.6, 0.8]) # buckets\n",
    "        \n",
    "        # reward generation based on (user âˆ™ game)\n",
    "        self._available_games = np.ones((nb_users, nb_games))\n",
    "        self._playtime = np.zeros((nb_users, nb_games))\n",
    "        self._reward_matrix = np.zeros((nb_users, nb_games))     \n",
    "        for i in range(self._reward_matrix.shape[0]):\n",
    "            for j in range(self._reward_matrix.shape[1]):\n",
    "                real_score = self._users[i].dot(self._games[j])\n",
    "                self._reward_matrix[i, j] = np.searchsorted(self.z_cut_points, real_score) + 1\n",
    "\n",
    "        users = deepcopy(self._users)\n",
    "        return users\n",
    "\n",
    "    def get_feature_vector(self, user, game):\n",
    "        user_embedding = self._users[user]\n",
    "        game_embedding = self._games[game]\n",
    "        \n",
    "        if self._displayed_users_embedding_size + self._displayed_games_embedding_size > 0:\n",
    "            variables = np.array([user_embedding[:self._displayed_users_embedding_size],\n",
    "                                  game_embedding[:self._displayed_games_embedding_size]])\n",
    "\n",
    "            if self._noise_size > 0:\n",
    "                noise = self._rng.normal(loc=np.ones(self._noise_size),\n",
    "                                         scale=np.ones(self._noise_size),\n",
    "                                         size=self._noise_size)\n",
    "                \n",
    "                variables = np.append(variables, noise)\n",
    "                \n",
    "        return variables\n",
    "        \n",
    "        \n",
    "    def reset_seed(self, seed=None):\n",
    "        self._rng = np.random.RandomState(seed)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "    def __init__(self, seed = None):\n",
    "        self._rng = np.random.RandomState(seed)\n",
    "    \n",
    "    def act(self, available_games):\n",
    "        action = self._rng.choice(available_games)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic parameter\n",
    "nb_users = 30 #number of users in the context = 30\n",
    "nb_games = 10 #number of games in the context = 10\n",
    "context_size = 2 #number of different film categories = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76884571,  1.07555227],\n",
       "       [-0.1306297 ,  0.34856983],\n",
       "       [ 0.10688437, -0.27410098],\n",
       "       [ 0.93884557,  1.06451384],\n",
       "       [ 1.41011295,  0.42711751],\n",
       "       [ 0.19866638,  2.31203519],\n",
       "       [ 2.27469887, -0.2143576 ],\n",
       "       [ 1.31371941, -0.44482142],\n",
       "       [ 0.6310387 ,  0.23077342],\n",
       "       [ 1.3926161 ,  1.05729383],\n",
       "       [ 3.08997884,  1.04197131],\n",
       "       [ 0.95165928,  0.48684608],\n",
       "       [ 0.91541072, -0.21545008],\n",
       "       [-0.41293073, -0.48691055],\n",
       "       [ 1.38222486,  1.937673  ],\n",
       "       [ 2.77267804,  1.87882801],\n",
       "       [ 1.33171912,  0.69396433],\n",
       "       [ 2.24026615,  0.78437316],\n",
       "       [ 1.15592948,  1.09805553],\n",
       "       [ 1.83209585,  3.04520542],\n",
       "       [ 0.68318608, -0.31283291],\n",
       "       [-0.75445746,  1.10209408],\n",
       "       [-0.36150208,  1.48178488],\n",
       "       [ 0.79167126,  0.90813649],\n",
       "       [ 1.70268816,  1.10365506],\n",
       "       [ 1.62123638,  1.95411497],\n",
       "       [ 3.03781352,  0.51554878],\n",
       "       [ 1.2071549 ,  2.64424216],\n",
       "       [ 0.5117926 ,  0.98217174],\n",
       "       [ 1.46891556,  1.27987266]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the environment\n",
    "env = Environment(nb_games,nb_users,context_size,seed=2020)\n",
    "env.reset() #reset and initilize the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the agent\n",
    "agent = RandomAgent(2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the experiment and generate some historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating matrix: \n",
      " [[0. 0. 0. 3. 0. 0. 0. 2. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 2. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [2. 3. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [2. 0. 0. 0. 5. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 4. 2. 0. 0. 0. 0. 0.]\n",
      " [0. 3. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 4. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 0. 0. 0. 0. 0. 0. 2. 0.]\n",
      " [0. 0. 0. 2. 5. 0. 0. 3. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 2. 4. 5. 2.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 2.]\n",
      " [0. 0. 5. 0. 0. 0. 0. 4. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 3. 0. 2.]\n",
      " [0. 0. 0. 4. 5. 5. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 3. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 2. 0. 0. 0. 3. 3. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 4. 0. 0.]\n",
      " [0. 0. 0. 0. 5. 0. 0. 4. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 4. 0. 0. 4. 0.]\n",
      " [3. 0. 0. 0. 4. 0. 0. 0. 0. 0.]\n",
      " [0. 3. 0. 0. 3. 3. 0. 0. 0. 2.]\n",
      " [0. 0. 0. 0. 5. 0. 0. 4. 0. 0.]]\n",
      "playtime: \n",
      " [[  0   0   0  75   0   0  35   7   0   0]\n",
      " [ 15   0   0   0   0   0   0   0   0   0]\n",
      " [  0  17   5   0   0   0   0   0   0   0]\n",
      " [ 29  54   0   0  66   0   0   0   0   0]\n",
      " [ 29   0   0   0 100   0   0   0  69   0]\n",
      " [  0   0  13  75  22   0   0   0   0  34]\n",
      " [  0  51   0  17   0   0   7  51   0   0]\n",
      " [  0   0  89   0   0   0   0   0   0   0]\n",
      " [  0   7  41   0  44   0   3   0  18  34]\n",
      " [  0   0   0  56  92   0   0  66   0  18]\n",
      " [  0   0   0   0   0   0  17   0   0   0]\n",
      " [  0  22   0   0   0   0   8  43   0   0]\n",
      " [  0  31   0   4   0   0   0   0   0   0]\n",
      " [  0   0  28   9  13   0   8   7   0   0]\n",
      " [  0   0   0  58   0   0  17  90  75   2]\n",
      " [ 53   0   0   0  89   0   0   0   0   0]\n",
      " [  0   0   0   0   0  65   0   0   0  26]\n",
      " [ 32   0 100   0 100  85   0 100   0   0]\n",
      " [ 17   0   0   0   0   0  40  41  85  78]\n",
      " [ 40  88   0 100  95 100   0   0 100  26]\n",
      " [ 56   0   0  15   0  33   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0]\n",
      " [ 21   0  33  55  31  82   0   0   0   1]\n",
      " [  0   0   0  24   0   0   0  42  56   0]\n",
      " [  0  19   0   0   0   0   0  59  62   0]\n",
      " [ 35   0   0   0 100   0   0  72   0   0]\n",
      " [  0   0   0   0   0  27   0   0  70   0]\n",
      " [ 71   0   0   0  70   0   0 100   0   0]\n",
      " [  0  38   0   0  64  19   0  66   0  19]\n",
      " [ 57   0   0   0 100   0   0  93   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Running several trials\n",
    "nb_iteration = 100 #how many trials\n",
    "rating_matrix = np.zeros((env._nb_users, env._nb_games))\n",
    "playtime_matrix = np.zeros((env._nb_users, env._nb_games))\n",
    "users = list()\n",
    "games = list()\n",
    "ratings = list()\n",
    "for i in range(nb_iteration):\n",
    "    user, available_games, _, finish = env.step()\n",
    "    if finish:\n",
    "        print(\"Maybe too many trial try to reduce and reset the environment\")\n",
    "        break\n",
    "    choosen_game = agent.act(available_games)\n",
    "    reward, playtime = env.update(user, choosen_game)\n",
    "    users.append(user)\n",
    "    games.append(choosen_game)\n",
    "    ratings.append(reward)\n",
    "    rating_matrix[user, choosen_game] = reward\n",
    "    playtime_matrix[user, choosen_game] = playtime\n",
    "    '''\n",
    "    print(\"user = {}, recommended_games = {}, choosen_game = {}\".format(user,recommended_games,choosen_game))\n",
    "    print(\"reward = {}\\n\".format(reward))\n",
    "    '''\n",
    "    \n",
    "print(\"rating matrix: \\n\", str(rating_matrix))\n",
    "print(\"playtime: \\n\", str(np.int8(playtime_matrix * 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(Model):\n",
    "    def __init__(self, embedding_size, max_user, max_game):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_embedding = Embedding(output_dim=embedding_size,\n",
    "                                        input_dim=max_user,\n",
    "                                        input_length=1,\n",
    "                                        name='user_embedding')\n",
    "        self.game_embedding = Embedding(output_dim=embedding_size,\n",
    "                                        input_dim=max_game,\n",
    "                                        input_length=1,\n",
    "                                        name='game_embedding')\n",
    "        self.flatten = Flatten()\n",
    "        self.dot = Dot(axes=1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        user_inputs = inputs[0]\n",
    "        game_inputs = inputs[1]\n",
    "        \n",
    "        user_vecs = self.flatten(self.user_embedding(user_inputs))\n",
    "        game_vecs = self.flatten(self.game_embedding(game_inputs))\n",
    "        \n",
    "        y = self.dot([user_vecs, game_vecs])\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepRegressionModel(Model):\n",
    "\n",
    "    def __init__(self, embedding_size, max_user, max_game):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_embedding = Embedding(output_dim=embedding_size,\n",
    "                                        input_dim=max_user,\n",
    "                                        input_length=1,\n",
    "                                        name='user_embedding')\n",
    "        self.game_embedding = Embedding(output_dim=embedding_size,\n",
    "                                        input_dim=max_game,\n",
    "                                        input_length=1,\n",
    "                                        name='game_embedding')\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.concat = Concatenate()\n",
    "        \n",
    "        self.dense1 = Dense(16, activation=\"relu\")\n",
    "        self.dense2 = Dense(8, activation=\"relu\")\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        featureVector = True\n",
    "        user_inputs = inputs[0]\n",
    "        game_inputs = inputs[1]\n",
    "        feature_inputs = inputs[2]\n",
    "        \n",
    "        user_vecs = self.flatten(self.user_embedding(user_inputs))\n",
    "        game_vecs = self.flatten(self.game_embedding(game_inputs))\n",
    "        \n",
    "        if featureVector:\n",
    "            input_vecs = self.concat([user_vecs, game_vecs, self.flatten(feature_inputs)])\n",
    "        else:\n",
    "            input_vecs = self.concat([user_vecs, game_vecs])\n",
    "        \n",
    "        y = self.dense1(input_vecs)\n",
    "        y = self.dense2(y)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingAgent:\n",
    "    def __init__(self, X, Y, deepRegression=False):\n",
    "        if deepRegression:\n",
    "            self._model = DeepRegressionModel(64, nb_users, nb_games) ## passare nb\n",
    "        else:\n",
    "            self._model = RegressionModel(64, nb_users, nb_games)\n",
    "        self._model.compile(optimizer=\"adam\", loss='mae')\n",
    "        self._model.fit(X, Y,\n",
    "                  batch_size=64, epochs=100, validation_split=0.1,\n",
    "                  shuffle=True)\n",
    "        self._user_embeddings = self._model.get_weights()[0]\n",
    "        self._game_embeddings = self._model.get_weights()[1]\n",
    "    \n",
    "    def act(self, user, available_games):\n",
    "        user_embedding = self._user_embeddings[user]\n",
    "        dot_products = self._game_embeddings @ user_embedding\n",
    "        user_embedding_norm = np.linalg.norm(user_embedding)\n",
    "        all_item_norms = np.linalg.norm(self._game_embeddings, axis=1)\n",
    "        norm_products = user_embedding_norm * all_item_norms\n",
    "        sims = dot_products / (norm_products)\n",
    "        sims = np.argsort(sims)[::-1]\n",
    "        mask = np.in1d(sims, available_games)\n",
    "        sims = sims[mask]\n",
    "        return sims[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 0s 1ms/sample - loss: 2.6206 - val_loss: 2.8360\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 0s 671us/sample - loss: 2.5986 - val_loss: 2.8161\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 0s 713us/sample - loss: 2.5751 - val_loss: 2.7941\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 0s 672us/sample - loss: 2.5506 - val_loss: 2.7691\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 0s 706us/sample - loss: 2.5250 - val_loss: 2.7429\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 0s 754us/sample - loss: 2.4980 - val_loss: 2.7142\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 0s 703us/sample - loss: 2.4695 - val_loss: 2.6846\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 0s 741us/sample - loss: 2.4390 - val_loss: 2.6534\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 0s 726us/sample - loss: 2.4075 - val_loss: 2.6202\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 0s 731us/sample - loss: 2.3729 - val_loss: 2.5844\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 0s 795us/sample - loss: 2.3365 - val_loss: 2.5457\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 0s 893us/sample - loss: 2.2976 - val_loss: 2.5046\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 0s 852us/sample - loss: 2.2573 - val_loss: 2.4617\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 0s 810us/sample - loss: 2.2138 - val_loss: 2.4164\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 0s 735us/sample - loss: 2.1678 - val_loss: 2.3686\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 0s 694us/sample - loss: 2.1200 - val_loss: 2.3182\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 0s 717us/sample - loss: 2.0687 - val_loss: 2.2657\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 0s 871us/sample - loss: 2.0161 - val_loss: 2.2110\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 0s 729us/sample - loss: 1.9607 - val_loss: 2.1537\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 0s 735us/sample - loss: 1.9024 - val_loss: 2.0936\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 0s 712us/sample - loss: 1.8414 - val_loss: 2.0321\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 0s 742us/sample - loss: 1.7811 - val_loss: 1.9721\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 0s 818us/sample - loss: 1.7199 - val_loss: 1.9098\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 0s 804us/sample - loss: 1.6571 - val_loss: 1.8452\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 0s 912us/sample - loss: 1.5945 - val_loss: 1.7786\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 0s 853us/sample - loss: 1.5342 - val_loss: 1.7127\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 0s 859us/sample - loss: 1.4762 - val_loss: 1.6446\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 0s 812us/sample - loss: 1.4193 - val_loss: 1.5822\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 0s 855us/sample - loss: 1.3630 - val_loss: 1.5212\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 0s 811us/sample - loss: 1.3067 - val_loss: 1.4601\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 0s 881us/sample - loss: 1.2577 - val_loss: 1.3993\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 0s 867us/sample - loss: 1.2096 - val_loss: 1.3411\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 0s 719us/sample - loss: 1.1622 - val_loss: 1.2882\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 0s 777us/sample - loss: 1.1233 - val_loss: 1.2355\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 0s 678us/sample - loss: 1.0861 - val_loss: 1.1829\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 0s 719us/sample - loss: 1.0539 - val_loss: 1.1330\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 0s 836us/sample - loss: 1.0241 - val_loss: 1.0884\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 0s 670us/sample - loss: 0.9936 - val_loss: 1.0484\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 0s 755us/sample - loss: 0.9687 - val_loss: 1.0121\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 0s 674us/sample - loss: 0.9446 - val_loss: 0.9834\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 0s 780us/sample - loss: 0.9219 - val_loss: 0.9573\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 0s 705us/sample - loss: 0.9022 - val_loss: 0.9347\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 0s 672us/sample - loss: 0.8832 - val_loss: 0.9140\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 0s 772us/sample - loss: 0.8641 - val_loss: 0.8948\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 0s 743us/sample - loss: 0.8462 - val_loss: 0.8780\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 0s 768us/sample - loss: 0.8272 - val_loss: 0.8629\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 0s 711us/sample - loss: 0.8066 - val_loss: 0.8489\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 0s 661us/sample - loss: 0.7863 - val_loss: 0.8368\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 0s 881us/sample - loss: 0.7679 - val_loss: 0.8268\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 0s 741us/sample - loss: 0.7483 - val_loss: 0.8166\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 0s 664us/sample - loss: 0.7320 - val_loss: 0.8054\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 0s 658us/sample - loss: 0.7161 - val_loss: 0.7934\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 0s 652us/sample - loss: 0.7025 - val_loss: 0.7813\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 0s 655us/sample - loss: 0.6878 - val_loss: 0.7696\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 0s 666us/sample - loss: 0.6744 - val_loss: 0.7569\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 0s 627us/sample - loss: 0.6615 - val_loss: 0.7439\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 0s 633us/sample - loss: 0.6489 - val_loss: 0.7308\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 0s 638us/sample - loss: 0.6381 - val_loss: 0.7163\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 0s 642us/sample - loss: 0.6289 - val_loss: 0.7028\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 0s 639us/sample - loss: 0.6177 - val_loss: 0.6911\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 0s 656us/sample - loss: 0.6097 - val_loss: 0.6816\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 0s 640us/sample - loss: 0.6006 - val_loss: 0.6735\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 0s 651us/sample - loss: 0.5940 - val_loss: 0.6657\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 0s 732us/sample - loss: 0.5872 - val_loss: 0.6591\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 0s 647us/sample - loss: 0.5801 - val_loss: 0.6531\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 0s 667us/sample - loss: 0.5754 - val_loss: 0.6469\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 0s 813us/sample - loss: 0.5709 - val_loss: 0.6420\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 0s 644us/sample - loss: 0.5647 - val_loss: 0.6399\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 0s 654us/sample - loss: 0.5600 - val_loss: 0.6403\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 0s 649us/sample - loss: 0.5551 - val_loss: 0.6423\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 0s 646us/sample - loss: 0.5507 - val_loss: 0.6453\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 0s 669us/sample - loss: 0.5469 - val_loss: 0.6510\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 0s 672us/sample - loss: 0.5433 - val_loss: 0.6572\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 0s 632us/sample - loss: 0.5398 - val_loss: 0.6641\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 0s 656us/sample - loss: 0.5379 - val_loss: 0.6712\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 0s 670us/sample - loss: 0.5345 - val_loss: 0.6772\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 0s 672us/sample - loss: 0.5311 - val_loss: 0.6846\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 0s 688us/sample - loss: 0.5282 - val_loss: 0.6913\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 0s 858us/sample - loss: 0.5254 - val_loss: 0.6966\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 0s 813us/sample - loss: 0.5233 - val_loss: 0.7017\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 0s 847us/sample - loss: 0.5214 - val_loss: 0.7080\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 0s 690us/sample - loss: 0.5194 - val_loss: 0.7148\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 0s 701us/sample - loss: 0.5170 - val_loss: 0.7221\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 0s 644us/sample - loss: 0.5146 - val_loss: 0.7306\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 0s 739us/sample - loss: 0.5122 - val_loss: 0.7385\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 0s 681us/sample - loss: 0.5106 - val_loss: 0.7458\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 0s 644us/sample - loss: 0.5082 - val_loss: 0.7522\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 0s 637us/sample - loss: 0.5060 - val_loss: 0.7586\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 0s 682us/sample - loss: 0.5042 - val_loss: 0.7644\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 0s 638us/sample - loss: 0.5022 - val_loss: 0.7710\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 0s 643us/sample - loss: 0.5001 - val_loss: 0.7775\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 0s 665us/sample - loss: 0.4984 - val_loss: 0.7854\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 0s 636us/sample - loss: 0.4968 - val_loss: 0.7928\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 0s 660us/sample - loss: 0.4947 - val_loss: 0.7992\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 0s 671us/sample - loss: 0.4937 - val_loss: 0.8060\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 0s 648us/sample - loss: 0.4921 - val_loss: 0.8110\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 0s 648us/sample - loss: 0.4900 - val_loss: 0.8138\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 0s 631us/sample - loss: 0.4886 - val_loss: 0.8160\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 0s 646us/sample - loss: 0.4871 - val_loss: 0.8193\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 0s 689us/sample - loss: 0.4858 - val_loss: 0.8232\n"
     ]
    }
   ],
   "source": [
    "deepRegression = True\n",
    "\n",
    "users = np.array(users)\n",
    "games = np.array(games)\n",
    "ratings = np.array(ratings)\n",
    "\n",
    "if deepRegression:\n",
    "    features = []\n",
    "    for i in range(len(users)):\n",
    "        features.append(env.get_feature_vector(users[i], games[i]))\n",
    "    features = np.float64(features)\n",
    "    agent = EmbeddingAgent([users, games, features], ratings, deepRegression=deepRegression)\n",
    "else:\n",
    "    agent = EmbeddingAgent([users, games], ratings, deepRegression=deepRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_env = deepcopy(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_iteration = 70\n",
    "nb_exp = 100\n",
    "#---------------#\n",
    "regret = np.zeros(nb_exp)\n",
    "cum_regret = np.zeros((nb_exp, nb_iteration))\n",
    "\n",
    "for t in range(nb_exp):\n",
    "    env = deepcopy(prev_env)\n",
    "    env.reset_seed()\n",
    "    regrets = np.zeros(nb_iteration)\n",
    "    for i in range(nb_iteration):\n",
    "        user, available_games, optimal_reward, finish = env.step()\n",
    "        if finish:\n",
    "            print(\"Maybe too many trial try to reduce and reset the environment\")\n",
    "            break\n",
    "        choosen_game = agent.act(user, available_games)\n",
    "        reward = env.update(user, choosen_game)\n",
    "        regrets[i] = optimal_reward - reward\n",
    "        # print(\"user = {}, available games = {}, choosen_game = {}\".format(user,available_games,choosen_game))\n",
    "        # print(\"reward = {}\\n\".format(reward))\n",
    "    cum_regret[t] = np.cumsum(regrets)\n",
    "    regret[t] = np.sum(regrets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cum_regret.mean(axis=0), color='blue')\n",
    "plt.plot(np.quantile(cum_regret, 0.05,axis=0), color='grey', alpha=0.5)\n",
    "plt.plot(np.quantile(cum_regret, 0.95,axis=0), color='grey', alpha=0.5)\n",
    "plt.title('Mean regret: {:.2f}'.format(regret.mean()))\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('regret')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
