{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steam (Environment - Agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "# Basic import\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import copy, deepcopy\n",
    "from scipy.stats import invgamma, gamma\n",
    "from scipy.stats import t as student\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout, Dot, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \"\"\" \n",
    "    Contextual Multi-Armed Bandit environment\n",
    "    \"\"\"\n",
    "    def __init__(self, nb_films, nb_users, context_size, \n",
    "                 displayed_users_embedding_size = 2, displayed_games_embedding_size = 2, noise_size = 3,\n",
    "                 seed=None):\n",
    "        self._nb_games = nb_games\n",
    "        self._nb_users = nb_users\n",
    "        self._p = context_size # size of user, size of game\n",
    "        self._displayed_users_embedding_size = displayed_users_embedding_size\n",
    "        self._displayed_games_embedding_size = displayed_games_embedding_size\n",
    "        self._noise_size = noise_size\n",
    "        self._rng = np.random.RandomState(seed)\n",
    "        self._games = self._rng.uniform(size=(nb_games, context_size))\n",
    "        self._users = self._rng.uniform(size=(nb_users, context_size))\n",
    "        self._reward_matrix = np.zeros((nb_users, nb_games))\n",
    "        for i in range(self._reward_matrix.shape[0]):\n",
    "            for j in range(self._reward_matrix.shape[1]):\n",
    "                reward = np.linalg.norm(self._games[j] - self._users[i], ord=2) \n",
    "                self._reward_matrix[i, j] = reward\n",
    "        self._reward_matrix = (self._reward_matrix / np.max(self._reward_matrix) * 4).astype(int) + 1\n",
    "        self._available_games = np.ones((nb_users, nb_games))\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\" Play an action \"\"\"\n",
    "        user = self._rng.randint(0, self._nb_users)\n",
    "        available_games = np.where(self._available_games[user] == 1)[0]\n",
    "        return user, available_games\n",
    "    \n",
    "    def update(self, user, game):\n",
    "        reward = self._reward_matrix[user, game]\n",
    "        self._available_games[user, game] = 0\n",
    "        return reward\n",
    "    \n",
    "    def reset(self):\n",
    "        self._users = self._rng.uniform(size=(self._nb_users, self._p))\n",
    "        self._reward_matrix = np.zeros((nb_users, nb_games))\n",
    "        for i in range(self._reward_matrix.shape[0]):\n",
    "            for j in range(self._reward_matrix.shape[1]):\n",
    "                reward = np.linalg.norm(self._games[j] - self._users[i], ord=2) \n",
    "                self._reward_matrix[i, j] = reward\n",
    "        self._reward_matrix = (self._reward_matrix / np.max(self._reward_matrix) * 4).astype(int) + 1\n",
    "        self._available_films = np.ones((nb_users, nb_games))\n",
    "        users = deepcopy(self._users)\n",
    "        return users\n",
    "\n",
    "    def get_feature_vector(self, user, game):\n",
    "        user_embedding = self._users[user]\n",
    "        game_embedding = self._games[game]\n",
    "        if self._displayed_users_embedding_size + self._displayed_games_embedding_size > 0:\n",
    "            variables = np.array([user_embedding[:self._displayed_users_embedding_size],\n",
    "                                  game_embedding[:self._displayed_games_embedding_size]])\n",
    "\n",
    "            if self._noise_size > 0:\n",
    "                noise = self._rng.normal(loc=np.ones(self._noise_size),\n",
    "                                         scale=np.ones(self._noise_size),\n",
    "                                         size=self._noise_size)\n",
    "                variables = np.append(variables, noise)\n",
    "            return variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "    \"\"\" \n",
    "    Random agent\n",
    "    \"\"\"\n",
    "    def __init__(self, seed = None):\n",
    "        self._rng = np.random.RandomState(seed)\n",
    "    \n",
    "    def act(self, available_games):\n",
    "        action = self._rng.choice(available_games)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic parameter\n",
    "nb_users = 30 #number of users in the context\n",
    "nb_games = 10 #number of games in the context\n",
    "context_size = 2 #number of different film categories = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61737096, 0.73475639],\n",
       "       [0.38388803, 0.36875855],\n",
       "       [0.42309307, 0.6716264 ],\n",
       "       [0.56404182, 0.60208195],\n",
       "       [0.97118069, 0.78576208],\n",
       "       [0.80525943, 0.64119836],\n",
       "       [0.16226102, 0.87445526],\n",
       "       [0.42063807, 0.9227937 ],\n",
       "       [0.8474458 , 0.0657038 ],\n",
       "       [0.91769485, 0.57255665],\n",
       "       [0.51947649, 0.84246567],\n",
       "       [0.9468588 , 0.56933799],\n",
       "       [0.74964656, 0.02829325],\n",
       "       [0.08538513, 0.39130871],\n",
       "       [0.99049897, 0.18968916],\n",
       "       [0.45562283, 0.12749988],\n",
       "       [0.31333326, 0.58755414],\n",
       "       [0.77318116, 0.0647224 ],\n",
       "       [0.11090496, 0.59787686],\n",
       "       [0.72206315, 0.90670112],\n",
       "       [0.94748654, 0.3978249 ],\n",
       "       [0.6064212 , 0.60574233],\n",
       "       [0.72796261, 0.99012723],\n",
       "       [0.43722955, 0.90822508],\n",
       "       [0.96696226, 0.90082751],\n",
       "       [0.5911972 , 0.87994122],\n",
       "       [0.12337073, 0.52186933],\n",
       "       [0.19760656, 0.01004305],\n",
       "       [0.48765934, 0.13587004],\n",
       "       [0.61096717, 0.5965448 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the environment\n",
    "env = Environment(nb_games,nb_users,context_size,2020)\n",
    "env.reset() #reset and initilize the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the agent\n",
    "agent = RandomAgent(2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the experiment and generate some historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating matrix: \n",
      " [[0. 2. 1. 1. 0. 0. 1. 0. 0. 2.]\n",
      " [2. 3. 2. 2. 0. 0. 0. 2. 0. 2.]\n",
      " [3. 2. 0. 2. 0. 2. 2. 1. 0. 0.]\n",
      " [0. 2. 0. 2. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 2. 2. 0. 1. 1. 3. 0. 0.]\n",
      " [2. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 3. 0. 1. 1. 0.]\n",
      " [3. 0. 0. 1. 0. 0. 0. 0. 0. 3.]\n",
      " [0. 0. 3. 3. 0. 3. 2. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 3. 0. 0.]\n",
      " [3. 2. 0. 1. 0. 2. 2. 0. 0. 3.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 3. 4. 0. 3. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 3. 0. 0. 0.]\n",
      " [1. 3. 0. 3. 0. 3. 2. 0. 3. 0.]\n",
      " [0. 4. 0. 3. 0. 4. 2. 0. 3. 0.]\n",
      " [3. 0. 0. 0. 0. 0. 0. 1. 0. 3.]\n",
      " [1. 0. 3. 3. 0. 0. 0. 0. 3. 0.]\n",
      " [4. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 0. 0. 0. 0. 0. 3. 0. 0.]\n",
      " [0. 2. 0. 0. 0. 0. 0. 2. 1. 0.]\n",
      " [3. 0. 0. 0. 1. 1. 0. 2. 0. 2.]\n",
      " [3. 2. 0. 1. 0. 2. 2. 0. 0. 3.]\n",
      " [0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 2. 0. 2. 0. 0. 0.]\n",
      " [0. 0. 3. 0. 0. 4. 0. 1. 2. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 3. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 4. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 2. 0. 0. 0. 0. 0. 2.]]\n"
     ]
    }
   ],
   "source": [
    "# Running several trials\n",
    "nb_iteration = 100 #how many trials\n",
    "rating_matrix = np.zeros((env._nb_users, env._nb_games))\n",
    "users = list()\n",
    "games = list()\n",
    "ratings = list()\n",
    "for i in range(nb_iteration):\n",
    "    user, available_games = env.step()\n",
    "    choosen_game = agent.act(available_games)\n",
    "    reward = env.update(user, choosen_game)\n",
    "    users.append(user)\n",
    "    games.append(choosen_game)\n",
    "    ratings.append(reward)\n",
    "    rating_matrix[user, choosen_game] = reward\n",
    "    '''\n",
    "    print(\"user = {}, recommended_games = {}, choosen_game = {}\".format(user,recommended_games,choosen_game))\n",
    "    print(\"reward = {}\\n\".format(reward))\n",
    "    '''\n",
    "    \n",
    "print(\"rating matrix: \\n\", str(rating_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(Model):\n",
    "    def __init__(self, embedding_size, max_user, max_game):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_embedding = Embedding(output_dim=embedding_size,\n",
    "                                        input_dim=max_user,\n",
    "                                        input_length=1,\n",
    "                                        name='user_embedding')\n",
    "        self.game_embedding = Embedding(output_dim=embedding_size,\n",
    "                                        input_dim=max_game,\n",
    "                                        input_length=1,\n",
    "                                        name='game_embedding')\n",
    "        \n",
    "        # The following two layers don't have parameters.\n",
    "        self.flatten = Flatten()\n",
    "        self.dot = Dot(axes=1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        user_inputs = inputs[0]\n",
    "        game_inputs = inputs[1]\n",
    "        \n",
    "        user_vecs = self.flatten(self.user_embedding(user_inputs))\n",
    "        game_vecs = self.flatten(self.game_embedding(game_inputs))\n",
    "        \n",
    "        y = self.dot([user_vecs, game_vecs])\n",
    "        return y\n",
    "\n",
    "model = RegressionModel(64, nb_users, nb_games)\n",
    "model.compile(optimizer=\"adam\", loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 0s 5ms/sample - loss: 2.4995 - val_loss: 1.8036\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 0s 130us/sample - loss: 2.4973 - val_loss: 1.8038\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 0s 121us/sample - loss: 2.4953 - val_loss: 1.8041\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 0s 167us/sample - loss: 2.4935 - val_loss: 1.8043\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 0s 187us/sample - loss: 2.4916 - val_loss: 1.8046\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 0s 204us/sample - loss: 2.4896 - val_loss: 1.8047\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 0s 206us/sample - loss: 2.4876 - val_loss: 1.8049\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 0s 192us/sample - loss: 2.4855 - val_loss: 1.8050\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 0s 178us/sample - loss: 2.4833 - val_loss: 1.8050\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 0s 172us/sample - loss: 2.4810 - val_loss: 1.8049\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 0s 194us/sample - loss: 2.4784 - val_loss: 1.8046\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 0s 203us/sample - loss: 2.4758 - val_loss: 1.8043\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 0s 197us/sample - loss: 2.4729 - val_loss: 1.8039\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 0s 218us/sample - loss: 2.4699 - val_loss: 1.8033\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 0s 140us/sample - loss: 2.4667 - val_loss: 1.8026\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 0s 205us/sample - loss: 2.4632 - val_loss: 1.8018\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 0s 234us/sample - loss: 2.4594 - val_loss: 1.8008\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 0s 209us/sample - loss: 2.4554 - val_loss: 1.7995\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 0s 181us/sample - loss: 2.4510 - val_loss: 1.7981\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 0s 206us/sample - loss: 2.4464 - val_loss: 1.7966\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 0s 218us/sample - loss: 2.4414 - val_loss: 1.7947\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 0s 212us/sample - loss: 2.4360 - val_loss: 1.7927\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 0s 203us/sample - loss: 2.4303 - val_loss: 1.7904\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 0s 187us/sample - loss: 2.4242 - val_loss: 1.7878\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 0s 182us/sample - loss: 2.4176 - val_loss: 1.7849\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 0s 197us/sample - loss: 2.4106 - val_loss: 1.7817\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 0s 175us/sample - loss: 2.4032 - val_loss: 1.7782\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 0s 196us/sample - loss: 2.3952 - val_loss: 1.7742\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 0s 185us/sample - loss: 2.3868 - val_loss: 1.7698\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 0s 199us/sample - loss: 2.3778 - val_loss: 1.7649\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 0s 185us/sample - loss: 2.3683 - val_loss: 1.7596\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 0s 222us/sample - loss: 2.3582 - val_loss: 1.7539\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 0s 240us/sample - loss: 2.3476 - val_loss: 1.7476\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 0s 177us/sample - loss: 2.3365 - val_loss: 1.7409\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 0s 223us/sample - loss: 2.3247 - val_loss: 1.7337\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 0s 206us/sample - loss: 2.3123 - val_loss: 1.7261\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 0s 204us/sample - loss: 2.2991 - val_loss: 1.7179\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 0s 197us/sample - loss: 2.2854 - val_loss: 1.7093\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 0s 187us/sample - loss: 2.2711 - val_loss: 1.7000\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 0s 221us/sample - loss: 2.2559 - val_loss: 1.6900\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 0s 174us/sample - loss: 2.2402 - val_loss: 1.6796\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 0s 189us/sample - loss: 2.2238 - val_loss: 1.6685\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 0s 173us/sample - loss: 2.2066 - val_loss: 1.6567\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 0s 195us/sample - loss: 2.1888 - val_loss: 1.6443\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 0s 203us/sample - loss: 2.1701 - val_loss: 1.6313\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 0s 193us/sample - loss: 2.1506 - val_loss: 1.6176\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 0s 203us/sample - loss: 2.1305 - val_loss: 1.6034\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 0s 198us/sample - loss: 2.1094 - val_loss: 1.5887\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 0s 217us/sample - loss: 2.0876 - val_loss: 1.5734\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 0s 196us/sample - loss: 2.0650 - val_loss: 1.5576\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 0s 210us/sample - loss: 2.0417 - val_loss: 1.5409\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 0s 202us/sample - loss: 2.0173 - val_loss: 1.5234\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 0s 200us/sample - loss: 1.9923 - val_loss: 1.5051\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 0s 166us/sample - loss: 1.9663 - val_loss: 1.4860\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 0s 146us/sample - loss: 1.9395 - val_loss: 1.4661\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 0s 179us/sample - loss: 1.9120 - val_loss: 1.4455\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 0s 231us/sample - loss: 1.8833 - val_loss: 1.4238\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 0s 206us/sample - loss: 1.8540 - val_loss: 1.4018\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 0s 224us/sample - loss: 1.8239 - val_loss: 1.3794\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 0s 197us/sample - loss: 1.7925 - val_loss: 1.3563\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 0s 160us/sample - loss: 1.7606 - val_loss: 1.3322\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 0s 205us/sample - loss: 1.7277 - val_loss: 1.3069\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 0s 188us/sample - loss: 1.6936 - val_loss: 1.2806\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 0s 213us/sample - loss: 1.6588 - val_loss: 1.2536\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 0s 184us/sample - loss: 1.6229 - val_loss: 1.2256\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 0s 193us/sample - loss: 1.5870 - val_loss: 1.1972\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 0s 211us/sample - loss: 1.5514 - val_loss: 1.1677\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 0s 184us/sample - loss: 1.5167 - val_loss: 1.1376\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 0s 141us/sample - loss: 1.4824 - val_loss: 1.1070\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 0s 154us/sample - loss: 1.4471 - val_loss: 1.0764\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 0s 140us/sample - loss: 1.4148 - val_loss: 1.0454\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 0s 148us/sample - loss: 1.3837 - val_loss: 1.0142\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 0s 158us/sample - loss: 1.3536 - val_loss: 0.9839\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 0s 176us/sample - loss: 1.3225 - val_loss: 0.9543\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 0s 181us/sample - loss: 1.2921 - val_loss: 0.9314\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 0s 158us/sample - loss: 1.2622 - val_loss: 0.9101\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 0s 154us/sample - loss: 1.2304 - val_loss: 0.8892\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 0s 133us/sample - loss: 1.1990 - val_loss: 0.8676\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 0s 139us/sample - loss: 1.1668 - val_loss: 0.8453\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 0s 142us/sample - loss: 1.1348 - val_loss: 0.8230\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 0s 170us/sample - loss: 1.1008 - val_loss: 0.8003\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 0s 179us/sample - loss: 1.0678 - val_loss: 0.7775\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 0s 169us/sample - loss: 1.0333 - val_loss: 0.7549\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 0s 169us/sample - loss: 0.9990 - val_loss: 0.7317\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 0s 163us/sample - loss: 0.9649 - val_loss: 0.7082\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 0s 158us/sample - loss: 0.9323 - val_loss: 0.6844\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 0s 176us/sample - loss: 0.9020 - val_loss: 0.6616\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 0s 132us/sample - loss: 0.8717 - val_loss: 0.6410\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 0s 124us/sample - loss: 0.8440 - val_loss: 0.6211\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 0s 150us/sample - loss: 0.8181 - val_loss: 0.6023\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 0s 168us/sample - loss: 0.7963 - val_loss: 0.5845\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 0s 169us/sample - loss: 0.7762 - val_loss: 0.5683\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 0s 166us/sample - loss: 0.7567 - val_loss: 0.5544\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 0s 164us/sample - loss: 0.7381 - val_loss: 0.5425\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 0s 158us/sample - loss: 0.7236 - val_loss: 0.5318\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 0s 143us/sample - loss: 0.7067 - val_loss: 0.5242\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 0s 125us/sample - loss: 0.6921 - val_loss: 0.5182\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 0s 151us/sample - loss: 0.6783 - val_loss: 0.5130\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 0s 168us/sample - loss: 0.6639 - val_loss: 0.5079\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 0s 159us/sample - loss: 0.6487 - val_loss: 0.5041\n"
     ]
    }
   ],
   "source": [
    "users = np.array(users)\n",
    "games = np.array(games)\n",
    "ratings = np.array(ratings)\n",
    "\n",
    "history = model.fit([users, games], ratings,\n",
    "                    batch_size=64, epochs=100, validation_split=0.1,\n",
    "                    shuffle=True)\n",
    "\n",
    "embeddings = model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(x, y):\n",
    "    dot = np.dot(x, y)\n",
    "    norm_x = np.linalg.norm(x)\n",
    "    norm_y = np.linalg.norm(y)\n",
    "    cos = dot / (norm_x * norm_y)\n",
    "    return cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingAgent:\n",
    "    \"\"\" \n",
    "    Embedding Agent\n",
    "    \"\"\"\n",
    "    def __init__(self, user_embeddings, game_embeddings):\n",
    "        self._game_embeddings = game_embeddings\n",
    "        self._user_embeddings = user_embeddings\n",
    "    \n",
    "    def act(self, user, available_games):\n",
    "        user_embedding = self._user_embeddings[user]\n",
    "        dot_products = self._game_embeddings @ user_embedding\n",
    "        user_embedding_norm = np.linalg.norm(user_embedding)\n",
    "        all_item_norms = np.linalg.norm(self._game_embeddings, axis=1)\n",
    "        norm_products = user_embedding_norm * all_item_norms\n",
    "        sims = dot_products / (norm_products)\n",
    "        sims = np.argsort(sims)[::-1]\n",
    "        mask = np.in1d(sims, available_games)\n",
    "        sims = sims[mask]\n",
    "        return sims[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying the embedding agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user = 6, available games = [0 2 3 5 6 8 9], choosen_game = 6\n",
      "reward = 3\n",
      "\n",
      "user = 18, available games = [1 2 5 6 7 8], choosen_game = 1\n",
      "reward = 3\n",
      "\n",
      "user = 29, available games = [0 4 5 7 8 9], choosen_game = 8\n",
      "reward = 3\n",
      "\n",
      "user = 19, available games = [0 1 2 3 4 5 9], choosen_game = 4\n",
      "reward = 1\n",
      "\n",
      "user = 12, available games = [0 1 2 4 5 6 7 8 9], choosen_game = 0\n",
      "reward = 2\n",
      "\n",
      "user = 25, available games = [1 2 3 4 6 7 8], choosen_game = 3\n",
      "reward = 2\n",
      "\n",
      "user = 8, available games = [0 1 3 5 7], choosen_game = 0\n",
      "reward = 2\n",
      "\n",
      "user = 26, available games = [2 3 4 5 7 9], choosen_game = 4\n",
      "reward = 3\n",
      "\n",
      "user = 29, available games = [0 4 5 7 9], choosen_game = 0\n",
      "reward = 3\n",
      "\n",
      "user = 7, available games = [1 3 4 5 7 8], choosen_game = 8\n",
      "reward = 3\n",
      "\n",
      "user = 25, available games = [1 2 4 6 7 8], choosen_game = 2\n",
      "reward = 3\n",
      "\n",
      "user = 16, available games = [2 4 5 6 7 8], choosen_game = 2\n",
      "reward = 2\n",
      "\n",
      "user = 20, available games = [1 2 6 8 9], choosen_game = 2\n",
      "reward = 3\n",
      "\n",
      "user = 25, available games = [1 4 6 7 8], choosen_game = 1\n",
      "reward = 2\n",
      "\n",
      "user = 8, available games = [1 3 5 7], choosen_game = 7\n",
      "reward = 3\n",
      "\n",
      "user = 24, available games = [1 3 4 5 6 7 8], choosen_game = 3\n",
      "reward = 2\n",
      "\n",
      "user = 14, available games = [0 1 2 4 5 6 7 9], choosen_game = 0\n",
      "reward = 3\n",
      "\n",
      "user = 11, available games = [0 1 2 3 5 7 8 9], choosen_game = 1\n",
      "reward = 3\n",
      "\n",
      "user = 17, available games = [1 3 4 5 7 8], choosen_game = 7\n",
      "reward = 2\n",
      "\n",
      "user = 26, available games = [2 3 5 7 9], choosen_game = 7\n",
      "reward = 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating the agent\n",
    "agent = EmbeddingAgent(embeddings[0], embeddings[1])\n",
    "\n",
    "# Running several trials\n",
    "nb_iteration = 20 #how many trials\n",
    "for i in range(nb_iteration):\n",
    "    user, available_games = env.step()\n",
    "    choosen_game = agent.act(user, available_games)\n",
    "    reward = env.update(user, choosen_game)\n",
    "    rating_matrix[user, choosen_game] = reward\n",
    "    print(\"user = {}, available games = {}, choosen_game = {}\".format(user,available_games,choosen_game))\n",
    "    print(\"reward = {}\\n\".format(reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepRegressionModel(Model):\n",
    "\n",
    "    def __init__(self, embedding_size, max_user, max_game):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_embedding = Embedding(output_dim=embedding_size,\n",
    "                                        input_dim=max_user,\n",
    "                                        input_length=1,\n",
    "                                        name='user_embedding')\n",
    "        self.game_embedding = Embedding(output_dim=embedding_size,\n",
    "                                        input_dim=max_game,\n",
    "                                        input_length=1,\n",
    "                                        name='game_embedding')\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.concat = Concatenate()\n",
    "        \n",
    "        self.dense1 = Dense(16, activation=\"relu\")\n",
    "        self.dense2 = Dense(8, activation=\"tanh\")\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        user_inputs = inputs[0]\n",
    "        game_inputs = inputs[1]\n",
    "        feature_inputs = inputs[2]\n",
    "        print(feature_inputs)\n",
    "\n",
    "        \n",
    "        user_vecs = self.flatten(self.user_embedding(user_inputs))\n",
    "        game_vecs = self.flatten(self.game_embedding(game_inputs))\n",
    "        \n",
    "        input_vecs = self.concat([user_vecs, game_vecs, self.flatten(feature_inputs)])\n",
    "        \n",
    "        y = self.dense1(input_vecs)\n",
    "        y = self.dense2(y)\n",
    "        \n",
    "        return y\n",
    "        \n",
    "model = DeepRegressionModel(64, nb_users, nb_games)\n",
    "model.compile(optimizer=\"adam\", loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_3:0\", shape=(None, 7), dtype=float32)\n",
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "Tensor(\"Cast:0\", shape=(None, 7), dtype=float32)\n",
      "Tensor(\"Cast:0\", shape=(None, 7), dtype=float32)\n",
      "64/90 [====================>.........] - ETA: 0s - loss: 2.2000Tensor(\"Cast:0\", shape=(None, 7), dtype=float32)\n",
      "90/90 [==============================] - 1s 6ms/sample - loss: 2.2155 - val_loss: 1.6526\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 0s 115us/sample - loss: 2.1973 - val_loss: 1.6333\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 0s 180us/sample - loss: 2.1791 - val_loss: 1.6140\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 0s 202us/sample - loss: 2.1615 - val_loss: 1.5945\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 0s 213us/sample - loss: 2.1436 - val_loss: 1.5754\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 0s 193us/sample - loss: 2.1256 - val_loss: 1.5560\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 0s 204us/sample - loss: 2.1078 - val_loss: 1.5365\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 0s 203us/sample - loss: 2.0895 - val_loss: 1.5173\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 0s 218us/sample - loss: 2.0709 - val_loss: 1.4976\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 0s 220us/sample - loss: 2.0519 - val_loss: 1.4772\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 0s 228us/sample - loss: 2.0323 - val_loss: 1.4563\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 0s 177us/sample - loss: 2.0122 - val_loss: 1.4344\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 0s 193us/sample - loss: 1.9911 - val_loss: 1.4119\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 0s 187us/sample - loss: 1.9693 - val_loss: 1.3887\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 0s 223us/sample - loss: 1.9465 - val_loss: 1.3650\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 0s 206us/sample - loss: 1.9231 - val_loss: 1.3404\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 0s 196us/sample - loss: 1.8985 - val_loss: 1.3152\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 0s 210us/sample - loss: 1.8733 - val_loss: 1.2896\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 0s 210us/sample - loss: 1.8469 - val_loss: 1.2634\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 0s 202us/sample - loss: 1.8196 - val_loss: 1.2366\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 0s 220us/sample - loss: 1.7912 - val_loss: 1.2090\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 0s 219us/sample - loss: 1.7618 - val_loss: 1.1801\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 0s 241us/sample - loss: 1.7311 - val_loss: 1.1502\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 0s 202us/sample - loss: 1.6997 - val_loss: 1.1192\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 0s 184us/sample - loss: 1.6671 - val_loss: 1.0883\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 0s 210us/sample - loss: 1.6343 - val_loss: 1.0575\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 0s 234us/sample - loss: 1.6010 - val_loss: 1.0275\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 0s 235us/sample - loss: 1.5681 - val_loss: 0.9977\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 0s 220us/sample - loss: 1.5356 - val_loss: 0.9674\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 0s 256us/sample - loss: 1.5045 - val_loss: 0.9387\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 0s 221us/sample - loss: 1.4744 - val_loss: 0.9116\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 0s 220us/sample - loss: 1.4464 - val_loss: 0.8862\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 0s 190us/sample - loss: 1.4204 - val_loss: 0.8632\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 0s 218us/sample - loss: 1.3967 - val_loss: 0.8425\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 0s 254us/sample - loss: 1.3754 - val_loss: 0.8241\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 0s 203us/sample - loss: 1.3566 - val_loss: 0.8079\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 0s 207us/sample - loss: 1.3397 - val_loss: 0.7939\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 0s 208us/sample - loss: 1.3250 - val_loss: 0.7817\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 0s 243us/sample - loss: 1.3122 - val_loss: 0.7712\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 0s 204us/sample - loss: 1.3012 - val_loss: 0.7622\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 0s 199us/sample - loss: 1.2917 - val_loss: 0.7545\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 0s 215us/sample - loss: 1.2835 - val_loss: 0.7480\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 0s 196us/sample - loss: 1.2764 - val_loss: 0.7425\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 0s 225us/sample - loss: 1.2704 - val_loss: 0.7377\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 0s 224us/sample - loss: 1.2652 - val_loss: 0.7337\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 0s 207us/sample - loss: 1.2608 - val_loss: 0.7302\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 0s 209us/sample - loss: 1.2569 - val_loss: 0.7272\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 0s 194us/sample - loss: 1.2536 - val_loss: 0.7247\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 0s 216us/sample - loss: 1.2508 - val_loss: 0.7225\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 0s 201us/sample - loss: 1.2483 - val_loss: 0.7206\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 0s 212us/sample - loss: 1.2462 - val_loss: 0.7189\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 0s 161us/sample - loss: 1.2443 - val_loss: 0.7174\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 0s 130us/sample - loss: 1.2426 - val_loss: 0.7161\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 0s 203us/sample - loss: 1.2411 - val_loss: 0.7150\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 0s 166us/sample - loss: 1.2399 - val_loss: 0.7140\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 0s 189us/sample - loss: 1.2387 - val_loss: 0.7131\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 0s 165us/sample - loss: 1.2377 - val_loss: 0.7123\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 0s 165us/sample - loss: 1.2368 - val_loss: 0.7115\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 0s 172us/sample - loss: 1.2359 - val_loss: 0.7109\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 0s 163us/sample - loss: 1.2352 - val_loss: 0.7103\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 0s 185us/sample - loss: 1.2345 - val_loss: 0.7097\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 0s 175us/sample - loss: 1.2339 - val_loss: 0.7092\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 0s 173us/sample - loss: 1.2333 - val_loss: 0.7088\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 0s 168us/sample - loss: 1.2328 - val_loss: 0.7084\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 0s 206us/sample - loss: 1.2323 - val_loss: 0.7080\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 0s 167us/sample - loss: 1.2318 - val_loss: 0.7077\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 0s 170us/sample - loss: 1.2314 - val_loss: 0.7073\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 0s 180us/sample - loss: 1.2311 - val_loss: 0.7070\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 0s 180us/sample - loss: 1.2307 - val_loss: 0.7068\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 0s 180us/sample - loss: 1.2304 - val_loss: 0.7065\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 0s 178us/sample - loss: 1.2301 - val_loss: 0.7062\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 0s 178us/sample - loss: 1.2298 - val_loss: 0.7060\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 0s 172us/sample - loss: 1.2295 - val_loss: 0.7058\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 0s 175us/sample - loss: 1.2292 - val_loss: 0.7056\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 0s 185us/sample - loss: 1.2290 - val_loss: 0.7054\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 0s 179us/sample - loss: 1.2288 - val_loss: 0.7052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "90/90 [==============================] - 0s 174us/sample - loss: 1.2286 - val_loss: 0.7050\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 0s 176us/sample - loss: 1.2284 - val_loss: 0.7049\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 0s 157us/sample - loss: 1.2282 - val_loss: 0.7047\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 0s 165us/sample - loss: 1.2280 - val_loss: 0.7046\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 0s 170us/sample - loss: 1.2278 - val_loss: 0.7044\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 0s 166us/sample - loss: 1.2276 - val_loss: 0.7043\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 0s 167us/sample - loss: 1.2275 - val_loss: 0.7042\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 0s 171us/sample - loss: 1.2273 - val_loss: 0.7041\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 0s 171us/sample - loss: 1.2272 - val_loss: 0.7040\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 0s 179us/sample - loss: 1.2270 - val_loss: 0.7039\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 0s 187us/sample - loss: 1.2269 - val_loss: 0.7037\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 0s 163us/sample - loss: 1.2268 - val_loss: 0.7036\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 0s 168us/sample - loss: 1.2267 - val_loss: 0.7036\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 0s 167us/sample - loss: 1.2265 - val_loss: 0.7035\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 0s 147us/sample - loss: 1.2264 - val_loss: 0.7034\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 0s 127us/sample - loss: 1.2263 - val_loss: 0.7033\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 0s 158us/sample - loss: 1.2262 - val_loss: 0.7032\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 0s 162us/sample - loss: 1.2261 - val_loss: 0.7031\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 0s 173us/sample - loss: 1.2260 - val_loss: 0.7031\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 0s 164us/sample - loss: 1.2259 - val_loss: 0.7030\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 0s 171us/sample - loss: 1.2259 - val_loss: 0.7029\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 0s 172us/sample - loss: 1.2258 - val_loss: 0.7028\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 0s 167us/sample - loss: 1.2257 - val_loss: 0.7028\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 0s 167us/sample - loss: 1.2256 - val_loss: 0.7027\n"
     ]
    }
   ],
   "source": [
    "users = np.array(users)\n",
    "games = np.array(games)\n",
    "ratings = np.array(ratings)\n",
    "\n",
    "features = []\n",
    "for i in range(len(users)):\n",
    "    features.append(env.get_feature_vector(users[i], games[i]))\n",
    "features = np.float64(features)\n",
    "\n",
    "history = model.fit([users, games, features], ratings,\n",
    "                    batch_size=64, epochs=100, validation_split=0.1,\n",
    "                    shuffle=True)\n",
    "\n",
    "embeddings = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user = 25, available games = [0 1 2 5 7 8 9], choosen_game = 2\n",
      "reward = 1\n",
      "\n",
      "user = 19, available games = [0 1 2 3 4 5 6 7 8 9], choosen_game = 7\n",
      "reward = 2\n",
      "\n",
      "user = 10, available games = [2 4 7 8], choosen_game = 2\n",
      "reward = 1\n",
      "\n",
      "user = 13, available games = [0 1 2 3 4 5 7 8 9], choosen_game = 9\n",
      "reward = 3\n",
      "\n",
      "user = 1, available games = [4 5 6 8], choosen_game = 8\n",
      "reward = 2\n",
      "\n",
      "user = 18, available games = [1 2 3 4 5 6 7 8 9], choosen_game = 2\n",
      "reward = 3\n",
      "\n",
      "user = 19, available games = [0 1 2 3 4 5 6 8 9], choosen_game = 8\n",
      "reward = 2\n",
      "\n",
      "user = 19, available games = [0 1 2 3 4 5 6 9], choosen_game = 4\n",
      "reward = 1\n",
      "\n",
      "user = 2, available games = [2 4 8 9], choosen_game = 9\n",
      "reward = 2\n",
      "\n",
      "user = 8, available games = [0 1 4 7 8 9], choosen_game = 9\n",
      "reward = 2\n",
      "\n",
      "user = 6, available games = [0 1 2 3 4 6 9], choosen_game = 9\n",
      "reward = 4\n",
      "\n",
      "user = 4, available games = [0 4 8 9], choosen_game = 9\n",
      "reward = 2\n",
      "\n",
      "user = 10, available games = [4 7 8], choosen_game = 8\n",
      "reward = 1\n",
      "\n",
      "user = 15, available games = [0 2 4 7 9], choosen_game = 9\n",
      "reward = 3\n",
      "\n",
      "user = 6, available games = [0 1 2 3 4 6], choosen_game = 2\n",
      "reward = 2\n",
      "\n",
      "user = 3, available games = [0 2 4 5 6 7 9], choosen_game = 9\n",
      "reward = 2\n",
      "\n",
      "user = 24, available games = [0 1 2 3 6 7 8 9], choosen_game = 9\n",
      "reward = 2\n",
      "\n",
      "user = 3, available games = [0 2 4 5 6 7], choosen_game = 2\n",
      "reward = 1\n",
      "\n",
      "user = 13, available games = [0 1 2 3 4 5 7 8], choosen_game = 2\n",
      "reward = 3\n",
      "\n",
      "user = 11, available games = [0 1 2 3 5 6 7 8 9], choosen_game = 9\n",
      "reward = 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating the agent\n",
    "agent = EmbeddingAgent(embeddings[0], embeddings[1])\n",
    "\n",
    "# Running several trials\n",
    "nb_iteration = 20 #how many trials\n",
    "for i in range(nb_iteration):\n",
    "    user, available_games = env.step()\n",
    "    choosen_game = agent.act(user, available_games)\n",
    "    reward = env.update(user, choosen_game)\n",
    "    rating_matrix[user, choosen_game] = reward\n",
    "    print(\"user = {}, available games = {}, choosen_game = {}\".format(user,available_games,choosen_game))\n",
    "    print(\"reward = {}\\n\".format(reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
