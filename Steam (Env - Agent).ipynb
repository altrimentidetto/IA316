{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steam (Environment - Agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "# Basic import\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from scipy.stats import norm\n",
    "import pdb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout, Dot, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \"\"\" \n",
    "    Contextual Multi-Armed Bandit environment\n",
    "    \"\"\"\n",
    "    def __init__(self, nb_films, nb_users, \n",
    "                 context_size = 2,\n",
    "                 displayed_users_embedding_size = 2, #used for the features vector\n",
    "                 displayed_games_embedding_size = 2, #used for the features vector\n",
    "                 noise_size = 3,\n",
    "                 seed=None):     \n",
    "        \n",
    "        self._rng = np.random.RandomState(seed)\n",
    "        #-------------------------------------------------------#\n",
    "        \n",
    "        self._nb_games = nb_games\n",
    "        self._nb_users = nb_users\n",
    "        self._p = context_size # size of user, size of game\n",
    "        self._displayed_users_embedding_size = displayed_users_embedding_size\n",
    "        self._displayed_games_embedding_size = displayed_games_embedding_size\n",
    "        self._noise_size = noise_size\n",
    "   \n",
    "        #-------------------------------------------------------#\n",
    "    \n",
    "        self.user_mean = np.ones(self._p)\n",
    "        self.user_var = np.ones(self._p)\n",
    "        self.game_mean = np.ones(self._p)\n",
    "        self.game_var = np.ones(self._p)\n",
    "        \n",
    "        #-------------------------------------------------------#\n",
    "        self.finish = False # flag to know when reset the environment (all games played)\n",
    "    \n",
    "    def step(self):\n",
    "        \n",
    "        if self.finish:\n",
    "            print(\"All games played reset the environment\")\n",
    "            \n",
    "        \"\"\" Choose a game \"\"\"\n",
    "        user = self._rng.randint(0, self._nb_users)\n",
    "        available_games = np.where(self._available_games[user] == 1)[0]\n",
    "        return user, available_games\n",
    "    \n",
    "    def update(self, user, game):\n",
    "        reward = self._reward_matrix[user, game]\n",
    "        self._available_games[user, game] = 0\n",
    "        return reward\n",
    "    \n",
    "    def reset(self):\n",
    "        self._users = self._rng.normal(loc=self.user_mean,\n",
    "                                                scale=self.user_var,\n",
    "                                                size=(self._nb_users, self._p))\n",
    "        self._games = self._rng.normal(loc=self.game_mean,\n",
    "                                                scale=self.game_var,\n",
    "                                                size=(self._nb_games, self._p))\n",
    "        \n",
    "        z_mean = self.user_mean.dot(self.game_mean)\n",
    "        z_var = self.user_var.dot(self.game_var) + self.user_var.dot(np.square(self.game_mean)) + \\\n",
    "                self.game_var.dot(np.square(self.user_mean))\n",
    "        z = norm(z_mean, np.sqrt(z_var))\n",
    "        self.z_cut_points = z.ppf([0.2, 0.4, 0.6, 0.8]) # buckets\n",
    "        self._available_games = np.ones((nb_users, nb_games))        \n",
    "        \n",
    "        self._reward_matrix = np.zeros((nb_users, nb_games))\n",
    "        \n",
    "        for i in range(self._reward_matrix.shape[0]):\n",
    "            for j in range(self._reward_matrix.shape[1]):\n",
    "                real_score = self._users[i].dot(self._games[j])\n",
    "                self._reward_matrix[i, j] = np.searchsorted(self.z_cut_points, real_score) + 1\n",
    "\n",
    "        users = deepcopy(self._users)\n",
    "        return users\n",
    "\n",
    "    def get_feature_vector(self, user, game):\n",
    "        user_embedding = self._users[user]\n",
    "        game_embedding = self._games[game]\n",
    "        \n",
    "        if self._displayed_users_embedding_size + self._displayed_games_embedding_size > 0:\n",
    "            variables = np.array([user_embedding[:self._displayed_users_embedding_size],\n",
    "                                  game_embedding[:self._displayed_games_embedding_size]])\n",
    "\n",
    "            if self._noise_size > 0:\n",
    "                noise = self._rng.normal(loc=np.ones(self._noise_size),\n",
    "                                         scale=np.ones(self._noise_size),\n",
    "                                         size=self._noise_size)\n",
    "                \n",
    "                variables = np.append(variables, noise)\n",
    "                \n",
    "            return variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "    \"\"\" \n",
    "    Random agent\n",
    "    \"\"\"\n",
    "    def __init__(self, seed = None):\n",
    "        self._rng = np.random.RandomState(seed)\n",
    "    \n",
    "    def act(self, available_games):\n",
    "        action = self._rng.choice(available_games)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic parameter\n",
    "nb_users = 30 #number of users in the context\n",
    "nb_games = 10 #number of games in the context\n",
    "context_size = 2 #number of different film categories = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76884571,  1.07555227],\n",
       "       [-0.1306297 ,  0.34856983],\n",
       "       [ 0.10688437, -0.27410098],\n",
       "       [ 0.93884557,  1.06451384],\n",
       "       [ 1.41011295,  0.42711751],\n",
       "       [ 0.19866638,  2.31203519],\n",
       "       [ 2.27469887, -0.2143576 ],\n",
       "       [ 1.31371941, -0.44482142],\n",
       "       [ 0.6310387 ,  0.23077342],\n",
       "       [ 1.3926161 ,  1.05729383],\n",
       "       [ 3.08997884,  1.04197131],\n",
       "       [ 0.95165928,  0.48684608],\n",
       "       [ 0.91541072, -0.21545008],\n",
       "       [-0.41293073, -0.48691055],\n",
       "       [ 1.38222486,  1.937673  ],\n",
       "       [ 2.77267804,  1.87882801],\n",
       "       [ 1.33171912,  0.69396433],\n",
       "       [ 2.24026615,  0.78437316],\n",
       "       [ 1.15592948,  1.09805553],\n",
       "       [ 1.83209585,  3.04520542],\n",
       "       [ 0.68318608, -0.31283291],\n",
       "       [-0.75445746,  1.10209408],\n",
       "       [-0.36150208,  1.48178488],\n",
       "       [ 0.79167126,  0.90813649],\n",
       "       [ 1.70268816,  1.10365506],\n",
       "       [ 1.62123638,  1.95411497],\n",
       "       [ 3.03781352,  0.51554878],\n",
       "       [ 1.2071549 ,  2.64424216],\n",
       "       [ 0.5117926 ,  0.98217174],\n",
       "       [ 1.46891556,  1.27987266]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the environment\n",
    "env = Environment(nb_games,nb_users,context_size,seed=2020)\n",
    "env.reset() #reset and initilize the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the agent\n",
    "agent = RandomAgent(2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the experiment and generate some historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating matrix: \n",
      " [[0. 0. 0. 3. 0. 0. 0. 2. 2. 0.]\n",
      " [0. 0. 1. 2. 1. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 2. 0. 0. 0. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 3. 0. 0. 0. 0.]\n",
      " [0. 3. 4. 2. 0. 0. 0. 3. 3. 2.]\n",
      " [0. 3. 0. 0. 0. 0. 3. 0. 5. 1.]\n",
      " [2. 0. 5. 1. 5. 3. 0. 0. 3. 3.]\n",
      " [0. 2. 4. 0. 0. 2. 0. 0. 0. 0.]\n",
      " [2. 2. 2. 0. 0. 2. 0. 2. 2. 2.]\n",
      " [2. 0. 0. 2. 5. 4. 0. 0. 4. 2.]\n",
      " [0. 4. 0. 0. 5. 0. 0. 4. 0. 0.]\n",
      " [0. 2. 3. 2. 0. 0. 0. 0. 0. 0.]\n",
      " [2. 0. 3. 0. 4. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      " [2. 0. 0. 0. 0. 0. 0. 4. 5. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 5. 0.]\n",
      " [0. 0. 0. 2. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 4. 0. 0. 0. 0. 0. 4. 0. 0.]\n",
      " [2. 0. 3. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [3. 5. 0. 4. 0. 0. 0. 5. 5. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [2. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 0. 0. 1. 3. 2. 0. 3. 0.]\n",
      " [0. 0. 3. 0. 0. 0. 2. 0. 0. 0.]\n",
      " [2. 0. 0. 0. 0. 0. 0. 0. 0. 2.]\n",
      " [0. 0. 0. 3. 5. 0. 2. 4. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 4. 1. 0. 4. 0.]\n",
      " [3. 0. 0. 4. 4. 0. 2. 0. 5. 2.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 3. 0.]\n",
      " [0. 3. 4. 2. 0. 0. 0. 4. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Running several trials\n",
    "nb_iteration = 100 #how many trials\n",
    "rating_matrix = np.zeros((env._nb_users, env._nb_games))\n",
    "users = list()\n",
    "games = list()\n",
    "ratings = list()\n",
    "for i in range(nb_iteration):\n",
    "    user, available_games = env.step()\n",
    "    choosen_game = agent.act(available_games)\n",
    "    reward = env.update(user, choosen_game)\n",
    "    users.append(user)\n",
    "    games.append(choosen_game)\n",
    "    ratings.append(reward)\n",
    "    rating_matrix[user, choosen_game] = reward\n",
    "    '''\n",
    "    print(\"user = {}, recommended_games = {}, choosen_game = {}\".format(user,recommended_games,choosen_game))\n",
    "    print(\"reward = {}\\n\".format(reward))\n",
    "    '''\n",
    "    \n",
    "print(\"rating matrix: \\n\", str(rating_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(Model):\n",
    "    def __init__(self, embedding_size, max_user, max_game):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_embedding = Embedding(output_dim=embedding_size,\n",
    "                                        input_dim=max_user,\n",
    "                                        input_length=1,\n",
    "                                        name='user_embedding')\n",
    "        self.game_embedding = Embedding(output_dim=embedding_size,\n",
    "                                        input_dim=max_game,\n",
    "                                        input_length=1,\n",
    "                                        name='game_embedding')\n",
    "        self.flatten = Flatten()\n",
    "        self.dot = Dot(axes=1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        user_inputs = inputs[0]\n",
    "        game_inputs = inputs[1]\n",
    "        \n",
    "        user_vecs = self.flatten(self.user_embedding(user_inputs))\n",
    "        game_vecs = self.flatten(self.game_embedding(game_inputs))\n",
    "        \n",
    "        y = self.dot([user_vecs, game_vecs])\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepRegressionModel(Model):\n",
    "\n",
    "    def __init__(self, embedding_size, max_user, max_game):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_embedding = Embedding(output_dim=embedding_size,\n",
    "                                        input_dim=max_user,\n",
    "                                        input_length=1,\n",
    "                                        name='user_embedding')\n",
    "        self.game_embedding = Embedding(output_dim=embedding_size,\n",
    "                                        input_dim=max_game,\n",
    "                                        input_length=1,\n",
    "                                        name='game_embedding')\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.concat = Concatenate()\n",
    "        \n",
    "        self.dense1 = Dense(16, activation=\"relu\")\n",
    "        self.dense2 = Dense(8, activation=\"relu\")\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        user_inputs = inputs[0]\n",
    "        game_inputs = inputs[1]\n",
    "        feature_inputs = inputs[2]\n",
    "        \n",
    "        user_vecs = self.flatten(self.user_embedding(user_inputs))\n",
    "        game_vecs = self.flatten(self.game_embedding(game_inputs))\n",
    "        \n",
    "        # input_vecs = self.concat([user_vecs, game_vecs, self.flatten(feature_inputs)])\n",
    "        input_vecs = self.concat([user_vecs, game_vecs])\n",
    "        \n",
    "        y = self.dense1(input_vecs)\n",
    "        y = self.dense2(y)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingAgent:\n",
    "    def __init__(self, X, Y, deepRegression=False):\n",
    "        if deepRegression:\n",
    "            self._model = DeepRegressionModel(64, nb_users, nb_games) ## passare nb\n",
    "        else:\n",
    "            self._model = RegressionModel(64, nb_users, nb_games)\n",
    "        self._model.compile(optimizer=\"adam\", loss='mae')\n",
    "        self._model.fit(X, Y,\n",
    "                  batch_size=64, epochs=100, validation_split=0.1,\n",
    "                  shuffle=True)\n",
    "        self._user_embeddings = self._model.get_weights()[0]\n",
    "        self._game_embeddings = self._model.get_weights()[1]\n",
    "    \n",
    "    def act(self, user, available_games):\n",
    "        user_embedding = self._user_embeddings[user]\n",
    "        dot_products = self._game_embeddings @ user_embedding\n",
    "        user_embedding_norm = np.linalg.norm(user_embedding)\n",
    "        all_item_norms = np.linalg.norm(self._game_embeddings, axis=1)\n",
    "        norm_products = user_embedding_norm * all_item_norms\n",
    "        sims = dot_products / (norm_products)\n",
    "        sims = np.argsort(sims)[::-1]\n",
    "        mask = np.in1d(sims, available_games)\n",
    "        sims = sims[mask]\n",
    "        return sims[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 0s 2ms/sample - loss: 2.7536 - val_loss: 2.9734\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 0s 573us/sample - loss: 2.7467 - val_loss: 2.9654\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 0s 539us/sample - loss: 2.7394 - val_loss: 2.9571\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 0s 579us/sample - loss: 2.7315 - val_loss: 2.9485\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 0s 554us/sample - loss: 2.7231 - val_loss: 2.9391\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 0s 601us/sample - loss: 2.7140 - val_loss: 2.9292\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 0s 716us/sample - loss: 2.7044 - val_loss: 2.9188\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 0s 621us/sample - loss: 2.6940 - val_loss: 2.9077\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 0s 572us/sample - loss: 2.6828 - val_loss: 2.8956\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 0s 565us/sample - loss: 2.6710 - val_loss: 2.8826\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 0s 535us/sample - loss: 2.6578 - val_loss: 2.8687\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 0s 489us/sample - loss: 2.6436 - val_loss: 2.8536\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 0s 605us/sample - loss: 2.6281 - val_loss: 2.8370\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 0s 556us/sample - loss: 2.6112 - val_loss: 2.8189\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 0s 598us/sample - loss: 2.5925 - val_loss: 2.7991\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 0s 539us/sample - loss: 2.5721 - val_loss: 2.7772\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 0s 612us/sample - loss: 2.5496 - val_loss: 2.7533\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 0s 466us/sample - loss: 2.5246 - val_loss: 2.7273\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 0s 509us/sample - loss: 2.4972 - val_loss: 2.6985\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 0s 607us/sample - loss: 2.4671 - val_loss: 2.6666\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 0s 559us/sample - loss: 2.4337 - val_loss: 2.6313\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 0s 533us/sample - loss: 2.3971 - val_loss: 2.5922\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 0s 499us/sample - loss: 2.3566 - val_loss: 2.5493\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 0s 658us/sample - loss: 2.3118 - val_loss: 2.5020\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 0s 521us/sample - loss: 2.2636 - val_loss: 2.4505\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 0s 508us/sample - loss: 2.2116 - val_loss: 2.3943\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 0s 618us/sample - loss: 2.1566 - val_loss: 2.3337\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 0s 524us/sample - loss: 2.0975 - val_loss: 2.2684\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 0s 567us/sample - loss: 2.0353 - val_loss: 2.1979\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 0s 507us/sample - loss: 1.9700 - val_loss: 2.1228\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 0s 490us/sample - loss: 1.8994 - val_loss: 2.0429\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 0s 634us/sample - loss: 1.8273 - val_loss: 1.9579\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 0s 516us/sample - loss: 1.7533 - val_loss: 1.8727\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 0s 583us/sample - loss: 1.6814 - val_loss: 1.7915\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 0s 527us/sample - loss: 1.6129 - val_loss: 1.7107\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 0s 605us/sample - loss: 1.5506 - val_loss: 1.6294\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 0s 656us/sample - loss: 1.4896 - val_loss: 1.5475\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 0s 591us/sample - loss: 1.4273 - val_loss: 1.4733\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 0s 526us/sample - loss: 1.3683 - val_loss: 1.4091\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 0s 529us/sample - loss: 1.3218 - val_loss: 1.3470\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 0s 629us/sample - loss: 1.2790 - val_loss: 1.2893\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 0s 593us/sample - loss: 1.2375 - val_loss: 1.2317\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 0s 742us/sample - loss: 1.1997 - val_loss: 1.1764\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 0s 739us/sample - loss: 1.1570 - val_loss: 1.1281\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 0s 691us/sample - loss: 1.1157 - val_loss: 1.0811\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 0s 689us/sample - loss: 1.0715 - val_loss: 1.0355\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 0s 577us/sample - loss: 1.0245 - val_loss: 0.9899\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 0s 542us/sample - loss: 0.9797 - val_loss: 0.9435\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 0s 533us/sample - loss: 0.9352 - val_loss: 0.8988\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 0s 596us/sample - loss: 0.8920 - val_loss: 0.8594\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 0s 747us/sample - loss: 0.8514 - val_loss: 0.8220\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 0s 710us/sample - loss: 0.8112 - val_loss: 0.7856\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 0s 639us/sample - loss: 0.7753 - val_loss: 0.7494\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 0s 524us/sample - loss: 0.7429 - val_loss: 0.7140\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 0s 500us/sample - loss: 0.7159 - val_loss: 0.6862\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 0s 447us/sample - loss: 0.6901 - val_loss: 0.6655\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 0s 560us/sample - loss: 0.6673 - val_loss: 0.6496\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 0s 585us/sample - loss: 0.6473 - val_loss: 0.6379\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 0s 713us/sample - loss: 0.6315 - val_loss: 0.6307\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 0s 647us/sample - loss: 0.6143 - val_loss: 0.6277\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 0s 657us/sample - loss: 0.6022 - val_loss: 0.6269\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 0s 587us/sample - loss: 0.5926 - val_loss: 0.6276\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 0s 728us/sample - loss: 0.5829 - val_loss: 0.6295\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 0s 739us/sample - loss: 0.5739 - val_loss: 0.6329\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 0s 528us/sample - loss: 0.5654 - val_loss: 0.6384\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 0s 494us/sample - loss: 0.5589 - val_loss: 0.6463\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 0s 529us/sample - loss: 0.5517 - val_loss: 0.6554\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 0s 497us/sample - loss: 0.5461 - val_loss: 0.6669\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 0s 527us/sample - loss: 0.5400 - val_loss: 0.6816\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 0s 530us/sample - loss: 0.5348 - val_loss: 0.6967\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 0s 607us/sample - loss: 0.5301 - val_loss: 0.7139\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 0s 539us/sample - loss: 0.5251 - val_loss: 0.7318\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 0s 534us/sample - loss: 0.5204 - val_loss: 0.7495\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 0s 528us/sample - loss: 0.5170 - val_loss: 0.7674\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 0s 530us/sample - loss: 0.5138 - val_loss: 0.7842\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 0s 563us/sample - loss: 0.5103 - val_loss: 0.7985\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 0s 453us/sample - loss: 0.5072 - val_loss: 0.8113\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 0s 561us/sample - loss: 0.5048 - val_loss: 0.8206\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 554us/sample - loss: 0.5031 - val_loss: 0.8302\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 0s 547us/sample - loss: 0.5009 - val_loss: 0.8408\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 0s 550us/sample - loss: 0.4985 - val_loss: 0.8544\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 0s 556us/sample - loss: 0.4960 - val_loss: 0.8654\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 0s 542us/sample - loss: 0.4946 - val_loss: 0.8701\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 0s 562us/sample - loss: 0.4923 - val_loss: 0.8751\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 0s 483us/sample - loss: 0.4901 - val_loss: 0.8774\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 0s 487us/sample - loss: 0.4883 - val_loss: 0.8784\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 0s 506us/sample - loss: 0.4875 - val_loss: 0.8775\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 0s 530us/sample - loss: 0.4858 - val_loss: 0.8776\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 0s 475us/sample - loss: 0.4850 - val_loss: 0.8803\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 0s 462us/sample - loss: 0.4832 - val_loss: 0.8810\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 0s 483us/sample - loss: 0.4815 - val_loss: 0.8857\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 0s 471us/sample - loss: 0.4802 - val_loss: 0.8930\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 0s 530us/sample - loss: 0.4812 - val_loss: 0.8983\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 0s 461us/sample - loss: 0.4803 - val_loss: 0.8983\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 0s 480us/sample - loss: 0.4789 - val_loss: 0.8957\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 0s 525us/sample - loss: 0.4770 - val_loss: 0.8948\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 0s 452us/sample - loss: 0.4770 - val_loss: 0.9000\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 0s 455us/sample - loss: 0.4764 - val_loss: 0.9136\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 0s 531us/sample - loss: 0.4742 - val_loss: 0.9261\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 0s 490us/sample - loss: 0.4762 - val_loss: 0.9341\n"
     ]
    }
   ],
   "source": [
    "deepRegression = True\n",
    "\n",
    "users = np.array(users)\n",
    "games = np.array(games)\n",
    "ratings = np.array(ratings)\n",
    "\n",
    "if deepRegression:\n",
    "    features = []\n",
    "    for i in range(len(users)):\n",
    "        features.append(env.get_feature_vector(users[i], games[i]))\n",
    "    features = np.float64(features)\n",
    "    agent = EmbeddingAgent([users, games, features], ratings, deepRegression=deepRegression)\n",
    "else:\n",
    "    agent = EmbeddingAgent([users, games], ratings, deepRegression=deepRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user = 21, available games = [1 3 4 5 6 7 8 9], choosen_game = 4\n",
      "reward = 1.0\n",
      "\n",
      "user = 2, available games = [0 1 3 4 5 8 9], choosen_game = 5\n",
      "reward = 1.0\n",
      "\n",
      "user = 0, available games = [0 1 2 4 5 6 9], choosen_game = 5\n",
      "reward = 2.0\n",
      "\n",
      "user = 22, available games = [0 2 3 7 9], choosen_game = 7\n",
      "reward = 3.0\n",
      "\n",
      "user = 27, available games = [1 2 5 7], choosen_game = 5\n",
      "reward = 5.0\n",
      "\n",
      "user = 7, available games = [0 3 4 6 7 8 9], choosen_game = 8\n",
      "reward = 2.0\n",
      "\n",
      "user = 3, available games = [0 1 2 3 4 6 7 8 9], choosen_game = 4\n",
      "reward = 4.0\n",
      "\n",
      "user = 20, available games = [0 1 2 4 5 6 7 8 9], choosen_game = 0\n",
      "reward = 2.0\n",
      "\n",
      "user = 11, available games = [0 4 5 6 7 8 9], choosen_game = 5\n",
      "reward = 3.0\n",
      "\n",
      "user = 27, available games = [1 2 7], choosen_game = 2\n",
      "reward = 3.0\n",
      "\n",
      "user = 7, available games = [0 3 4 6 7 9], choosen_game = 7\n",
      "reward = 2.0\n",
      "\n",
      "user = 1, available games = [0 1 5 6 7 8], choosen_game = 1\n",
      "reward = 2.0\n",
      "\n",
      "user = 0, available games = [0 1 2 4 6 9], choosen_game = 4\n",
      "reward = 1.0\n",
      "\n",
      "user = 2, available games = [0 1 3 4 8 9], choosen_game = 1\n",
      "reward = 1.0\n",
      "\n",
      "user = 6, available games = [1 6 7], choosen_game = 7\n",
      "reward = 3.0\n",
      "\n",
      "user = 21, available games = [1 3 5 6 7 8 9], choosen_game = 8\n",
      "reward = 2.0\n",
      "\n",
      "user = 20, available games = [1 2 4 5 6 7 8 9], choosen_game = 4\n",
      "reward = 3.0\n",
      "\n",
      "user = 0, available games = [0 1 2 6 9], choosen_game = 9\n",
      "reward = 1.0\n",
      "\n",
      "user = 28, available games = [0 1 2 3 4 5 6 7 9], choosen_game = 0\n",
      "reward = 2.0\n",
      "\n",
      "user = 21, available games = [1 3 5 6 7 9], choosen_game = 1\n",
      "reward = 2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Running several trials\n",
    "nb_iteration = 20 #how many trials\n",
    "for i in range(nb_iteration):\n",
    "    user, available_games = env.step()\n",
    "    choosen_game = agent.act(user, available_games)\n",
    "    reward = env.update(user, choosen_game)\n",
    "    rating_matrix[user, choosen_game] = reward\n",
    "    print(\"user = {}, available games = {}, choosen_game = {}\".format(user,available_games,choosen_game))\n",
    "    print(\"reward = {}\\n\".format(reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
