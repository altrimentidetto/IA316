{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steam (Environment - Agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "# Basic import\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from scipy.stats import norm\n",
    "import pdb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout, Dot, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "print(tf.__version__)\n",
    "print(\"OOOOOOOK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \"\"\" \n",
    "    Contextual Multi-Armed Bandit environment\n",
    "    \"\"\"\n",
    "    def __init__(self, nb_films, nb_users, \n",
    "                 context_size = 2,\n",
    "                 displayed_users_embedding_size = 2, #used for the features vector\n",
    "                 displayed_games_embedding_size = 2, #used for the features vector\n",
    "                 noise_size = 3,\n",
    "                 seed=None):     \n",
    "        \n",
    "        self._rng = np.random.RandomState(seed)\n",
    "        #-------------------------------------------------------#\n",
    "        \n",
    "        self._nb_games = nb_games\n",
    "        self._nb_users = nb_users\n",
    "        self._p = context_size # size of user, size of game\n",
    "        self._displayed_users_embedding_size = displayed_users_embedding_size\n",
    "        self._displayed_games_embedding_size = displayed_games_embedding_size\n",
    "        self._noise_size = noise_size\n",
    "   \n",
    "        #-------------------------------------------------------#\n",
    "    \n",
    "        self.user_mean = np.ones(self._p)\n",
    "        self.user_var = np.ones(self._p)\n",
    "        self.game_mean = np.ones(self._p)\n",
    "        self.game_var = np.ones(self._p)\n",
    "        \n",
    "        #-------------------------------------------------------#\n",
    "        self.finish = False # flag to know when reset the environment (all games played)\n",
    "    \n",
    "    def step(self):\n",
    "        \n",
    "        if self._available_games.sum() == 0:#if all players played all games\n",
    "            self.finish = True\n",
    "            print(\"All games played reset the environment\")\n",
    "            return 0,0, self.finish\n",
    "            \n",
    "        \"\"\" Choose a game \"\"\"\n",
    "        user = self.get_next_user()#always a user that have at least one gama still to play\n",
    "        \n",
    "        \n",
    "        available_games = np.where(self._available_games[user] == 1)[0]\n",
    "        optimal_reward = np.max(self._reward_matrix[user,available_games])\n",
    "        return user, available_games, optimal_reward, self.finish\n",
    "    \n",
    "    def get_next_user(self):\n",
    "        \n",
    "        user = self._rng.randint(0, self._nb_users)\n",
    "        \n",
    "        if np.sum(self._available_games[user,:]) > 0:#still some games to play\n",
    "            return user\n",
    "        else:#all games played for the current user--> change and find a random one between the one who still have some games\n",
    "            row,cols = np.where(self._available_games == 1)\n",
    "            #pdb.set_trace()\n",
    "            ret = self._rng.choice(row)\n",
    "            return ret\n",
    "    \n",
    "    def update(self, user, game):\n",
    "        reward = self._reward_matrix[user, game]\n",
    "        self._available_games[user, game] = 0\n",
    "        return reward\n",
    "    \n",
    "    def reset(self):\n",
    "        self.finish = False\n",
    "        self._users = self._rng.normal(loc=self.user_mean,\n",
    "                                                scale=self.user_var,\n",
    "                                                size=(self._nb_users, self._p))\n",
    "        self._games = self._rng.normal(loc=self.game_mean,\n",
    "                                                scale=self.game_var,\n",
    "                                                size=(self._nb_games, self._p))\n",
    "        \n",
    "        z_mean = self.user_mean.dot(self.game_mean)\n",
    "        z_var = self.user_var.dot(self.game_var) + self.user_var.dot(np.square(self.game_mean)) + \\\n",
    "                self.game_var.dot(np.square(self.user_mean))\n",
    "        z = norm(z_mean, np.sqrt(z_var))\n",
    "        self.z_cut_points = z.ppf([0.2, 0.4, 0.6, 0.8]) # buckets\n",
    "        self._available_games = np.ones((nb_users, nb_games))        \n",
    "        \n",
    "        self._reward_matrix = np.zeros((nb_users, nb_games))\n",
    "        \n",
    "        for i in range(self._reward_matrix.shape[0]):\n",
    "            for j in range(self._reward_matrix.shape[1]):\n",
    "                real_score = self._users[i].dot(self._games[j])\n",
    "                self._reward_matrix[i, j] = np.searchsorted(self.z_cut_points, real_score) + 1\n",
    "\n",
    "        users = deepcopy(self._users)\n",
    "        return users\n",
    "\n",
    "    def get_feature_vector(self, user, game):\n",
    "        user_embedding = self._users[user]\n",
    "        game_embedding = self._games[game]\n",
    "        \n",
    "        if self._displayed_users_embedding_size + self._displayed_games_embedding_size > 0:\n",
    "            variables = np.array([user_embedding[:self._displayed_users_embedding_size],\n",
    "                                  game_embedding[:self._displayed_games_embedding_size]])\n",
    "\n",
    "            if self._noise_size > 0:\n",
    "                noise = self._rng.normal(loc=np.ones(self._noise_size),\n",
    "                                         scale=np.ones(self._noise_size),\n",
    "                                         size=self._noise_size)\n",
    "                \n",
    "                variables = np.append(variables, noise)\n",
    "                \n",
    "        return variables\n",
    "        \n",
    "        \n",
    "    def reset_seed(self, seed=None):\n",
    "        self._rng = np.random.RandomState(seed)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "    \"\"\" \n",
    "    Random agent\n",
    "    \"\"\"\n",
    "    def __init__(self, seed = None):\n",
    "        self._rng = np.random.RandomState(seed)\n",
    "    \n",
    "    def act(self, available_games):\n",
    "        action = self._rng.choice(available_games)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic parameter\n",
    "nb_users = 30 #number of users in the context\n",
    "nb_games = 10 #number of games in the context\n",
    "context_size = 2 #number of different film categories = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76884571,  1.07555227],\n",
       "       [-0.1306297 ,  0.34856983],\n",
       "       [ 0.10688437, -0.27410098],\n",
       "       [ 0.93884557,  1.06451384],\n",
       "       [ 1.41011295,  0.42711751],\n",
       "       [ 0.19866638,  2.31203519],\n",
       "       [ 2.27469887, -0.2143576 ],\n",
       "       [ 1.31371941, -0.44482142],\n",
       "       [ 0.6310387 ,  0.23077342],\n",
       "       [ 1.3926161 ,  1.05729383],\n",
       "       [ 3.08997884,  1.04197131],\n",
       "       [ 0.95165928,  0.48684608],\n",
       "       [ 0.91541072, -0.21545008],\n",
       "       [-0.41293073, -0.48691055],\n",
       "       [ 1.38222486,  1.937673  ],\n",
       "       [ 2.77267804,  1.87882801],\n",
       "       [ 1.33171912,  0.69396433],\n",
       "       [ 2.24026615,  0.78437316],\n",
       "       [ 1.15592948,  1.09805553],\n",
       "       [ 1.83209585,  3.04520542],\n",
       "       [ 0.68318608, -0.31283291],\n",
       "       [-0.75445746,  1.10209408],\n",
       "       [-0.36150208,  1.48178488],\n",
       "       [ 0.79167126,  0.90813649],\n",
       "       [ 1.70268816,  1.10365506],\n",
       "       [ 1.62123638,  1.95411497],\n",
       "       [ 3.03781352,  0.51554878],\n",
       "       [ 1.2071549 ,  2.64424216],\n",
       "       [ 0.5117926 ,  0.98217174],\n",
       "       [ 1.46891556,  1.27987266]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the environment\n",
    "env = Environment(nb_games,nb_users,context_size,seed=2020)\n",
    "env.reset() #reset and initilize the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the agent\n",
    "agent = RandomAgent(2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the experiment and generate some historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating matrix: \n",
      " [[0. 0. 0. 3. 0. 0. 0. 2. 2. 0.]\n",
      " [0. 0. 1. 2. 1. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 2. 0. 0. 0. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 3. 0. 0. 0. 0.]\n",
      " [0. 3. 4. 2. 0. 0. 0. 3. 3. 2.]\n",
      " [0. 3. 0. 0. 0. 0. 3. 0. 5. 1.]\n",
      " [2. 0. 5. 1. 5. 3. 0. 0. 3. 3.]\n",
      " [0. 2. 4. 0. 0. 2. 0. 0. 0. 0.]\n",
      " [2. 2. 2. 0. 0. 2. 0. 2. 2. 2.]\n",
      " [2. 0. 0. 2. 5. 4. 0. 0. 4. 2.]\n",
      " [0. 4. 0. 0. 5. 0. 0. 4. 0. 0.]\n",
      " [0. 2. 3. 2. 0. 0. 0. 0. 0. 0.]\n",
      " [2. 0. 3. 0. 4. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      " [2. 0. 0. 0. 0. 0. 0. 4. 5. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 5. 0.]\n",
      " [0. 0. 0. 2. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 4. 0. 0. 0. 0. 0. 4. 0. 0.]\n",
      " [2. 0. 3. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [3. 5. 0. 4. 0. 0. 0. 5. 5. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [2. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 0. 0. 1. 3. 2. 0. 3. 0.]\n",
      " [0. 0. 3. 0. 0. 0. 2. 0. 0. 0.]\n",
      " [2. 0. 0. 0. 0. 0. 0. 0. 0. 2.]\n",
      " [0. 0. 0. 3. 5. 0. 2. 4. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 4. 1. 0. 4. 0.]\n",
      " [3. 0. 0. 4. 4. 0. 2. 0. 5. 2.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 3. 0.]\n",
      " [0. 3. 4. 2. 0. 0. 0. 4. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Running several trials\n",
    "nb_iteration = 100 #how many trials\n",
    "rating_matrix = np.zeros((env._nb_users, env._nb_games))\n",
    "users = list()\n",
    "games = list()\n",
    "ratings = list()\n",
    "for i in range(nb_iteration):\n",
    "    user, available_games, _, finish = env.step()\n",
    "    if finish:\n",
    "        print(\"Maybe too many trial try to reduce and reset the environment\")\n",
    "        break\n",
    "    choosen_game = agent.act(available_games)\n",
    "    reward = env.update(user, choosen_game)\n",
    "    users.append(user)\n",
    "    games.append(choosen_game)\n",
    "    ratings.append(reward)\n",
    "    rating_matrix[user, choosen_game] = reward\n",
    "    '''\n",
    "    print(\"user = {}, recommended_games = {}, choosen_game = {}\".format(user,recommended_games,choosen_game))\n",
    "    print(\"reward = {}\\n\".format(reward))\n",
    "    '''\n",
    "    \n",
    "print(\"rating matrix: \\n\", str(rating_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(Model):\n",
    "    def __init__(self, embedding_size, max_user, max_game):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_embedding = Embedding(output_dim=embedding_size,\n",
    "                                        input_dim=max_user,\n",
    "                                        input_length=1,\n",
    "                                        name='user_embedding')\n",
    "        self.game_embedding = Embedding(output_dim=embedding_size,\n",
    "                                        input_dim=max_game,\n",
    "                                        input_length=1,\n",
    "                                        name='game_embedding')\n",
    "        self.flatten = Flatten()\n",
    "        self.dot = Dot(axes=1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        user_inputs = inputs[0]\n",
    "        game_inputs = inputs[1]\n",
    "        \n",
    "        user_vecs = self.flatten(self.user_embedding(user_inputs))\n",
    "        game_vecs = self.flatten(self.game_embedding(game_inputs))\n",
    "        \n",
    "        y = self.dot([user_vecs, game_vecs])\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepRegressionModel(Model):\n",
    "\n",
    "    def __init__(self, embedding_size, max_user, max_game):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_embedding = Embedding(output_dim=embedding_size,\n",
    "                                        input_dim=max_user,\n",
    "                                        input_length=1,\n",
    "                                        name='user_embedding')\n",
    "        self.game_embedding = Embedding(output_dim=embedding_size,\n",
    "                                        input_dim=max_game,\n",
    "                                        input_length=1,\n",
    "                                        name='game_embedding')\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.concat = Concatenate()\n",
    "        \n",
    "        self.dense1 = Dense(16, activation=\"relu\")\n",
    "        self.dense2 = Dense(8, activation=\"relu\")\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        user_inputs = inputs[0]\n",
    "        game_inputs = inputs[1]\n",
    "        feature_inputs = inputs[2]\n",
    "        \n",
    "        user_vecs = self.flatten(self.user_embedding(user_inputs))\n",
    "        game_vecs = self.flatten(self.game_embedding(game_inputs))\n",
    "        \n",
    "        # input_vecs = self.concat([user_vecs, game_vecs, self.flatten(feature_inputs)])\n",
    "        input_vecs = self.concat([user_vecs, game_vecs])\n",
    "        \n",
    "        y = self.dense1(input_vecs)\n",
    "        y = self.dense2(y)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingAgent:\n",
    "    def __init__(self, X, Y, deepRegression=False):\n",
    "        if deepRegression:\n",
    "            self._model = DeepRegressionModel(64, nb_users, nb_games) ## passare nb\n",
    "        else:\n",
    "            self._model = RegressionModel(64, nb_users, nb_games)\n",
    "        self._model.compile(optimizer=\"adam\", loss='mae')\n",
    "        self._model.fit(X, Y,\n",
    "                  batch_size=64, epochs=100, validation_split=0.1,\n",
    "                  shuffle=True)\n",
    "        self._user_embeddings = self._model.get_weights()[0]\n",
    "        self._game_embeddings = self._model.get_weights()[1]\n",
    "    \n",
    "    def act(self, user, available_games):\n",
    "        user_embedding = self._user_embeddings[user]\n",
    "        dot_products = self._game_embeddings @ user_embedding\n",
    "        user_embedding_norm = np.linalg.norm(user_embedding)\n",
    "        all_item_norms = np.linalg.norm(self._game_embeddings, axis=1)\n",
    "        norm_products = user_embedding_norm * all_item_norms\n",
    "        sims = dot_products / (norm_products)\n",
    "        sims = np.argsort(sims)[::-1]\n",
    "        mask = np.in1d(sims, available_games)\n",
    "        sims = sims[mask]\n",
    "        return sims[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 0s 1ms/sample - loss: 2.7487 - val_loss: 2.9799\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 0s 470us/sample - loss: 2.7392 - val_loss: 2.9713\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 0s 516us/sample - loss: 2.7289 - val_loss: 2.9617\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 0s 491us/sample - loss: 2.7177 - val_loss: 2.9509\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 0s 575us/sample - loss: 2.7059 - val_loss: 2.9390\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 0s 647us/sample - loss: 2.6928 - val_loss: 2.9259\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 0s 516us/sample - loss: 2.6789 - val_loss: 2.9120\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 0s 582us/sample - loss: 2.6638 - val_loss: 2.8970\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 0s 527us/sample - loss: 2.6474 - val_loss: 2.8808\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 0s 545us/sample - loss: 2.6296 - val_loss: 2.8632\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 0s 545us/sample - loss: 2.6101 - val_loss: 2.8441\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 0s 562us/sample - loss: 2.5888 - val_loss: 2.8234\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 0s 584us/sample - loss: 2.5656 - val_loss: 2.8009\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 0s 546us/sample - loss: 2.5403 - val_loss: 2.7764\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 0s 509us/sample - loss: 2.5128 - val_loss: 2.7498\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 0s 599us/sample - loss: 2.4826 - val_loss: 2.7207\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 0s 537us/sample - loss: 2.4498 - val_loss: 2.6890\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 0s 594us/sample - loss: 2.4139 - val_loss: 2.6546\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 0s 567us/sample - loss: 2.3748 - val_loss: 2.6171\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 0s 455us/sample - loss: 2.3323 - val_loss: 2.5761\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 0s 665us/sample - loss: 2.2867 - val_loss: 2.5313\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 0s 588us/sample - loss: 2.2403 - val_loss: 2.4823\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 0s 478us/sample - loss: 2.1906 - val_loss: 2.4295\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 0s 580us/sample - loss: 2.1378 - val_loss: 2.3728\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 0s 619us/sample - loss: 2.0850 - val_loss: 2.3117\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 0s 585us/sample - loss: 2.0276 - val_loss: 2.2469\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 0s 544us/sample - loss: 1.9681 - val_loss: 2.1781\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 0s 545us/sample - loss: 1.9053 - val_loss: 2.1055\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 0s 532us/sample - loss: 1.8427 - val_loss: 2.0341\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 0s 543us/sample - loss: 1.7847 - val_loss: 1.9641\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 0s 567us/sample - loss: 1.7254 - val_loss: 1.8945\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 0s 536us/sample - loss: 1.6714 - val_loss: 1.8269\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 0s 553us/sample - loss: 1.6167 - val_loss: 1.7614\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 0s 553us/sample - loss: 1.5656 - val_loss: 1.7003\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 0s 557us/sample - loss: 1.5152 - val_loss: 1.6393\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 0s 607us/sample - loss: 1.4697 - val_loss: 1.5790\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 0s 503us/sample - loss: 1.4245 - val_loss: 1.5245\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 0s 525us/sample - loss: 1.3838 - val_loss: 1.4763\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 0s 564us/sample - loss: 1.3467 - val_loss: 1.4321\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 0s 563us/sample - loss: 1.3117 - val_loss: 1.3898\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 0s 620us/sample - loss: 1.2770 - val_loss: 1.3516\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 0s 638us/sample - loss: 1.2432 - val_loss: 1.3151\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 0s 552us/sample - loss: 1.2088 - val_loss: 1.2785\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 0s 542us/sample - loss: 1.1774 - val_loss: 1.2413\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 0s 558us/sample - loss: 1.1448 - val_loss: 1.2057\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 0s 536us/sample - loss: 1.1141 - val_loss: 1.1737\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 0s 635us/sample - loss: 1.0862 - val_loss: 1.1455\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 0s 495us/sample - loss: 1.0604 - val_loss: 1.1206\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 0s 574us/sample - loss: 1.0363 - val_loss: 1.0980\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 0s 522us/sample - loss: 1.0142 - val_loss: 1.0769\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 0s 538us/sample - loss: 0.9928 - val_loss: 1.0566\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 0s 537us/sample - loss: 0.9738 - val_loss: 1.0362\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 0s 561us/sample - loss: 0.9565 - val_loss: 1.0195\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 0s 529us/sample - loss: 0.9406 - val_loss: 1.0067\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 0s 571us/sample - loss: 0.9242 - val_loss: 0.9950\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 0s 546us/sample - loss: 0.9112 - val_loss: 0.9833\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 0s 541us/sample - loss: 0.8973 - val_loss: 0.9771\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 0s 550us/sample - loss: 0.8831 - val_loss: 0.9730\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 0s 542us/sample - loss: 0.8713 - val_loss: 0.9702\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 0s 567us/sample - loss: 0.8599 - val_loss: 0.9689\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 0s 561us/sample - loss: 0.8500 - val_loss: 0.9670\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 0s 560us/sample - loss: 0.8410 - val_loss: 0.9653\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 0s 548us/sample - loss: 0.8338 - val_loss: 0.9633\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 0s 521us/sample - loss: 0.8275 - val_loss: 0.9623\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 0s 532us/sample - loss: 0.8223 - val_loss: 0.9619\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 0s 582us/sample - loss: 0.8165 - val_loss: 0.9619\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 0s 532us/sample - loss: 0.8124 - val_loss: 0.9630\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 0s 545us/sample - loss: 0.8071 - val_loss: 0.9647\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 0s 577us/sample - loss: 0.8042 - val_loss: 0.9693\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 0s 727us/sample - loss: 0.7994 - val_loss: 0.9743\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 0s 723us/sample - loss: 0.7964 - val_loss: 0.9806\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 0s 528us/sample - loss: 0.7939 - val_loss: 0.9891\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 0s 515us/sample - loss: 0.7907 - val_loss: 0.9985\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 0s 508us/sample - loss: 0.7887 - val_loss: 1.0090\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 0s 526us/sample - loss: 0.7862 - val_loss: 1.0212\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 0s 604us/sample - loss: 0.7828 - val_loss: 1.0345\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 0s 629us/sample - loss: 0.7818 - val_loss: 1.0465\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 0s 537us/sample - loss: 0.7785 - val_loss: 1.0572\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 0s 494us/sample - loss: 0.7769 - val_loss: 1.0670\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 0s 519us/sample - loss: 0.7754 - val_loss: 1.0770\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 0s 1ms/sample - loss: 0.7737 - val_loss: 1.0903\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 0s 617us/sample - loss: 0.7717 - val_loss: 1.1017\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 0s 448us/sample - loss: 0.7701 - val_loss: 1.1122\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 0s 615us/sample - loss: 0.7685 - val_loss: 1.1225\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 0s 735us/sample - loss: 0.7664 - val_loss: 1.1333\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 0s 736us/sample - loss: 0.7665 - val_loss: 1.1393\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 0s 725us/sample - loss: 0.7652 - val_loss: 1.1403\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 0s 549us/sample - loss: 0.7640 - val_loss: 1.1396\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 0s 517us/sample - loss: 0.7635 - val_loss: 1.1369\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 0s 522us/sample - loss: 0.7637 - val_loss: 1.1359\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 0s 589us/sample - loss: 0.7629 - val_loss: 1.1363\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 0s 759us/sample - loss: 0.7619 - val_loss: 1.1380\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 0s 757us/sample - loss: 0.7611 - val_loss: 1.1369\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 0s 754us/sample - loss: 0.7602 - val_loss: 1.1352\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 0s 750us/sample - loss: 0.7593 - val_loss: 1.1345\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 0s 524us/sample - loss: 0.7588 - val_loss: 1.1345\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 0s 572us/sample - loss: 0.7590 - val_loss: 1.1344\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 0s 528us/sample - loss: 0.7588 - val_loss: 1.1345\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 0s 526us/sample - loss: 0.7583 - val_loss: 1.1322\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 0s 548us/sample - loss: 0.7576 - val_loss: 1.1294\n"
     ]
    }
   ],
   "source": [
    "deepRegression = True\n",
    "\n",
    "users = np.array(users)\n",
    "games = np.array(games)\n",
    "ratings = np.array(ratings)\n",
    "\n",
    "if deepRegression:\n",
    "    features = []\n",
    "    for i in range(len(users)):\n",
    "        features.append(env.get_feature_vector(users[i], games[i]))\n",
    "    features = np.float64(features)\n",
    "    agent = EmbeddingAgent([users, games, features], ratings, deepRegression=deepRegression)\n",
    "else:\n",
    "    agent = EmbeddingAgent([users, games], ratings, deepRegression=deepRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_env = deepcopy(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_iteration = 50\n",
    "nb_exp = 100\n",
    "#---------------#\n",
    "regret = np.zeros(nb_exp)\n",
    "cum_regret = np.zeros((nb_exp, nb_iteration))\n",
    "\n",
    "for t in range(nb_exp):\n",
    "    env = deepcopy(prev_env)\n",
    "    env.reset_seed()\n",
    "    regrets = np.zeros(nb_iteration)\n",
    "    for i in range(nb_iteration):\n",
    "        user, available_games, optimal_reward, finish = env.step()\n",
    "        if finish:\n",
    "            print(\"Maybe too many trial try to reduce and reset the environment\")\n",
    "            break\n",
    "        choosen_game = agent.act(user, available_games)\n",
    "        reward = env.update(user, choosen_game)\n",
    "        regrets[i] = optimal_reward - reward\n",
    "        # print(\"user = {}, available games = {}, choosen_game = {}\".format(user,available_games,choosen_game))\n",
    "        # print(\"reward = {}\\n\".format(reward))\n",
    "    cum_regret[t] = np.cumsum(regrets)\n",
    "    regret[t] = np.sum(regrets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cum_regret.mean(axis=0), color='blue')\n",
    "plt.plot(np.quantile(cum_regret, 0.05,axis=0), color='grey', alpha=0.5)\n",
    "plt.plot(np.quantile(cum_regret, 0.95,axis=0), color='grey', alpha=0.5)\n",
    "plt.title('Mean regret: {:.2f}'.format(regret.mean()))\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('regret')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
